#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¿«é€Ÿæœç´¢å¼•æ“å¯¹æ¯”æµ‹è¯•è„šæœ¬

è¿™æ˜¯ä¸€ä¸ªç®€åŒ–ç‰ˆæœ¬ï¼Œç”¨äºå¿«é€ŸéªŒè¯ESå’ŒParadeDBçš„åŸºæœ¬æœç´¢åŠŸèƒ½
"""

import os
import sys
import time
import logging

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from rag import settings
from rag.utils.es_conn import ESConnection
from rag.utils.pd_conn import PDConnection
from rag.utils.doc_store_conn import MatchTextExpr, MatchDenseExpr, FusionExpr, OrderByExpr
import numpy as np

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def test_basic_search():
    """æµ‹è¯•åŸºæœ¬æœç´¢åŠŸèƒ½"""
    print("ğŸ” å¿«é€Ÿæœç´¢å¼•æ“å¯¹æ¯”æµ‹è¯•")
    print("=" * 40)
    
    # å°è¯•åŠ è½½è‡ªåŠ¨ç”Ÿæˆçš„é…ç½®
    try:
        from test_kb_config import TEST_CONFIG
        INDEX_NAME = TEST_CONFIG["index_name"]
        KB_IDS = TEST_CONFIG["kb_ids"]
        TEST_QUERY = TEST_CONFIG["test_queries"][0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªæµ‹è¯•æŸ¥è¯¢
        print("âœ… ä½¿ç”¨è‡ªåŠ¨ç”Ÿæˆçš„é…ç½®")
    except ImportError:
        # å¦‚æœæ²¡æœ‰é…ç½®æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤å€¼
        print("âš ï¸ æœªæ‰¾åˆ°test_kb_config.pyï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        print("ğŸ’¡ å»ºè®®å…ˆè¿è¡Œ python simple_kb_setup.py åˆ›å»ºæµ‹è¯•æ•°æ®")
        INDEX_NAME = "ragflow_6a2a5a8c00a611f0883a0242ac140006"
        KB_IDS = ["6a2a5a8c-00a6-11f0-883a-0242ac140006"]
        TEST_QUERY = "æœºå™¨äºº"
    
    print(f"ç´¢å¼•åç§°: {INDEX_NAME}")
    print(f"çŸ¥è¯†åº“ID: {KB_IDS}")
    print(f"æµ‹è¯•æŸ¥è¯¢: '{TEST_QUERY}'")
    print()
    
    # åˆå§‹åŒ–è¿æ¥
    es_conn = None
    pd_conn = None
    
    try:
        # å°è¯•è¿æ¥ES
        if hasattr(settings, 'ES') and settings.ES.get('hosts'):
            print("ğŸ”— è¿æ¥Elasticsearch...")
            es_conn = ESConnection()
            print("âœ… ESè¿æ¥æˆåŠŸ")
        else:
            print("âš ï¸ æœªé…ç½®ESï¼Œè·³è¿‡ESæµ‹è¯•")
    except Exception as e:
        print(f"âŒ ESè¿æ¥å¤±è´¥: {e}")
    
    try:
        # å°è¯•è¿æ¥ParadeDB
        if hasattr(settings, 'PARADEDB') and settings.PARADEDB.get('host'):
            print("ğŸ”— è¿æ¥ParadeDB...")
            pd_conn = PDConnection()
            print("âœ… ParadeDBè¿æ¥æˆåŠŸ")
        else:
            print("âš ï¸ æœªé…ç½®ParadeDBï¼Œè·³è¿‡ParadeDBæµ‹è¯•")
    except Exception as e:
        print(f"âŒ ParadeDBè¿æ¥å¤±è´¥: {e}")
    
    if not es_conn and not pd_conn:
        print("âŒ æ²¡æœ‰å¯ç”¨çš„æœç´¢å¼•æ“è¿æ¥")
        return
    
    print()
    
    # åˆ›å»ºæœç´¢è¡¨è¾¾å¼
    def create_simple_search(query_text):
        """åˆ›å»ºç®€å•çš„æ–‡æœ¬æœç´¢è¡¨è¾¾å¼"""
        return [MatchTextExpr(
            fields=["content_ltks^10", "title_tks^8", "content_with_weight^2"],
            matching_text=query_text,
            topn=10,
            extra_options={"minimum_should_match": 0.3}
        )]
    
    def create_hybrid_search(query_text):
        """åˆ›å»ºæ··åˆæœç´¢è¡¨è¾¾å¼"""
        expressions = []
        
        # æ–‡æœ¬æœç´¢
        text_expr = MatchTextExpr(
            fields=["content_ltks^10", "title_tks^8", "content_with_weight^2"],
            matching_text=query_text,
            topn=10,
            extra_options={"minimum_should_match": 0.3}
        )
        expressions.append(text_expr)
        
        # å‘é‡æœç´¢ï¼ˆä½¿ç”¨éšæœºå‘é‡è¿›è¡Œæµ‹è¯•ï¼‰
        np.random.seed(42)
        test_vector = np.random.normal(0, 1, 1024)
        test_vector = test_vector / np.linalg.norm(test_vector)
        
        vector_expr = MatchDenseExpr(
            vector_column_name="q_1024_vec",
            embedding_data=test_vector.tolist(),
            topn=10,
            extra_options={"similarity": 0.1}
        )
        expressions.append(vector_expr)
        
        # èåˆè¡¨è¾¾å¼
        fusion_expr = FusionExpr(
            method="weighted_sum",
            topn=10,
            fusion_params={"weights": "0.5, 0.5"}
        )
        expressions.append(fusion_expr)
        
        return expressions
    
    # æµ‹è¯•ä¸åŒçš„æœç´¢æ–¹å¼
    test_cases = [
        ("çº¯æ–‡æœ¬æœç´¢", create_simple_search(TEST_QUERY)),
        ("æ··åˆæœç´¢", create_hybrid_search(TEST_QUERY))
    ]
    
    for test_name, match_exprs in test_cases:
        print(f"ğŸ§ª æµ‹è¯•: {test_name}")
        print("-" * 30)
        
        # ESæœç´¢
        if es_conn:
            try:
                start_time = time.time()
                es_res = es_conn.search(
                    selectFields=["id", "content_with_weight"],
                    highlightFields=[],
                    condition={"available_int": 1},
                    matchExprs=match_exprs,
                    orderBy=OrderByExpr(),
                    offset=0,
                    limit=5,
                    indexNames=INDEX_NAME,
                    knowledgebaseIds=KB_IDS
                )
                es_time = time.time() - start_time
                
                es_hits = es_res.get("hits", {}).get("hits", [])
                print(f"ESç»“æœ: {len(es_hits)}æ¡, è€—æ—¶{es_time:.3f}ç§’")
                
                for i, hit in enumerate(es_hits[:3]):
                    doc_id = hit.get("_id", "")[:20] + "..."
                    score = hit.get("_score", 0)
                    print(f"  {i+1}. {doc_id} (åˆ†æ•°: {score:.3f})")
                    
            except Exception as e:
                print(f"ESæœç´¢å¤±è´¥: {e}")
        
        # ParadeDBæœç´¢
        if pd_conn:
            try:
                start_time = time.time()
                pd_res = pd_conn.search(
                    selectFields=["id", "content_with_weight"],
                    highlightFields=[],
                    condition={"available_int": 1},
                    matchExprs=match_exprs,
                    orderBy=OrderByExpr(),
                    offset=0,
                    limit=5,
                    indexNames=INDEX_NAME,
                    knowledgebaseIds=KB_IDS
                )
                pd_time = time.time() - start_time
                
                pd_hits = pd_res.get("hits", {}).get("hits", [])
                print(f"ParadeDBç»“æœ: {len(pd_hits)}æ¡, è€—æ—¶{pd_time:.3f}ç§’")
                
                for i, hit in enumerate(pd_hits[:3]):
                    doc_id = hit.get("_id", "")[:20] + "..."
                    score = hit.get("_score", 0)
                    print(f"  {i+1}. {doc_id} (åˆ†æ•°: {score:.3f})")
                    
            except Exception as e:
                print(f"ParadeDBæœç´¢å¤±è´¥: {e}")
        
        # ç®€å•å¯¹æ¯”
        if es_conn and pd_conn:
            try:
                es_hits = es_res.get("hits", {}).get("hits", [])
                pd_hits = pd_res.get("hits", {}).get("hits", [])
                
                es_ids = set(hit.get("_id", "") for hit in es_hits)
                pd_ids = set(hit.get("_id", "") for hit in pd_hits)
                
                common_docs = len(es_ids & pd_ids)
                total_docs = max(len(es_ids), len(pd_ids))
                overlap_rate = common_docs / total_docs if total_docs > 0 else 0
                
                print(f"ğŸ“Š å¿«é€Ÿå¯¹æ¯”:")
                print(f"  å…±åŒæ–‡æ¡£: {common_docs}/{total_docs}")
                print(f"  é‡å ç‡: {overlap_rate*100:.1f}%")
                
                # æ£€æŸ¥Top-1æ˜¯å¦ç›¸åŒ
                if es_hits and pd_hits:
                    es_top1 = es_hits[0].get("_id", "")
                    pd_top1 = pd_hits[0].get("_id", "")
                    top1_match = "âœ…" if es_top1 == pd_top1 else "âŒ"
                    print(f"  Top-1åŒ¹é…: {top1_match}")
                
            except Exception as e:
                print(f"å¯¹æ¯”åˆ†æå¤±è´¥: {e}")
        
        print()

def main():
    """ä¸»å‡½æ•°"""
    try:
        test_basic_search()
        print("âœ… å¿«é€Ÿæµ‹è¯•å®Œæˆ")
        print("\nğŸ’¡ æç¤º: å¦‚éœ€è¯¦ç»†åˆ†æï¼Œè¯·ä½¿ç”¨ compare_search_engines.py")
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 