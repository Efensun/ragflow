#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¿«é€Ÿæœç´¢å¼•æ“å¯¹æ¯”æµ‹è¯•è„šæœ¬ï¼ˆæ”¯æŒçœŸå®embeddingå‘é‡ï¼‰

è¿™æ˜¯ä¸€ä¸ªç®€åŒ–ç‰ˆæœ¬ï¼Œç”¨äºå¿«é€ŸéªŒè¯ESå’ŒParadeDBçš„åŸºæœ¬æœç´¢åŠŸèƒ½ï¼Œä½¿ç”¨çœŸå®embeddingè¿›è¡Œè¯­ä¹‰æœç´¢æµ‹è¯•
"""

import os
import sys
import time
import logging
from typing import List

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from rag import settings
from rag.utils.es_conn import ESConnection
from rag.utils.pd_conn import PDConnection
from rag.utils.doc_store_conn import MatchTextExpr, MatchDenseExpr, FusionExpr, OrderByExpr
import numpy as np

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class QuickSearchTester:
    """å¿«é€Ÿæœç´¢æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.es_conn = None
        self.pd_conn = None
        self.embedding_model = None
        self.vector_dimension = 1024  # é»˜è®¤å‘é‡ç»´åº¦
        self.init_connections()
        self.init_embedding_model()
    
    def init_connections(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¿æ¥"""
        try:
            # åˆå§‹åŒ–ESè¿æ¥
            if hasattr(settings, 'ES') and settings.ES.get('hosts'):
                print("ğŸ”— è¿æ¥Elasticsearch...")
                self.es_conn = ESConnection()
                print("âœ… ESè¿æ¥æˆåŠŸ")
            else:
                print("âš ï¸ æœªé…ç½®ESï¼Œè·³è¿‡ESæµ‹è¯•")
        except Exception as e:
            print(f"âŒ ESè¿æ¥å¤±è´¥: {e}")
        
        try:
            # åˆå§‹åŒ–ParadeDBè¿æ¥
            if hasattr(settings, 'PARADEDB') and settings.PARADEDB.get('host'):
                print("ğŸ”— è¿æ¥ParadeDB...")
                self.pd_conn = PDConnection()
                print("âœ… ParadeDBè¿æ¥æˆåŠŸ")
            else:
                print("âš ï¸ æœªé…ç½®ParadeDBï¼Œè·³è¿‡ParadeDBæµ‹è¯•")
        except Exception as e:
            print(f"âŒ ParadeDBè¿æ¥å¤±è´¥: {e}")
    
    def init_embedding_model(self):
        """åˆå§‹åŒ–embeddingæ¨¡å‹"""
        try:
            # æ–¹æ³•1: ç›´æ¥ä½¿ç”¨OpenAIå®¢æˆ·ç«¯è°ƒç”¨Xinference
            try:
                from openai import OpenAI
                
                xinference_client = OpenAI(
                    api_key="empty", 
                    base_url="http://120.77.38.66:8008/v1"
                )
                
                test_response = xinference_client.embeddings.create(
                    input=["æµ‹è¯•æ–‡æœ¬"],
                    model="jina-embeddings-v3"
                )
                
                if test_response.data and len(test_response.data[0].embedding) > 0:
                    self.embedding_model = xinference_client
                    self.vector_dimension = len(test_response.data[0].embedding)
                    print(f"âœ… ä½¿ç”¨OpenAIå®¢æˆ·ç«¯è°ƒç”¨Xinference jina-embeddings-v3æ¨¡å‹ï¼Œå‘é‡ç»´åº¦: {self.vector_dimension}")
                    return
                    
            except Exception as e:
                logger.warning(f"æ— æ³•ä½¿ç”¨OpenAIå®¢æˆ·ç«¯è°ƒç”¨Xinference: {e}")
            
            # å¦‚æœæ‰€æœ‰æ–¹æ¡ˆéƒ½å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿå‘é‡
            logger.info("âš ï¸ æ— æ³•åŠ è½½ä»»ä½•çœŸå®embeddingæ¨¡å‹ï¼Œä½¿ç”¨æ¨¡æ‹Ÿå‘é‡è¿›è¡Œæµ‹è¯•")
            self.embedding_model = None
            self.vector_dimension = 1024
            
        except Exception as e:
            logger.error(f"âŒ embeddingæ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            self.embedding_model = None
            self.vector_dimension = 1024
    
    def generate_embedding(self, text: str) -> List[float]:
        """ç”Ÿæˆæ–‡æœ¬çš„embeddingå‘é‡"""
        try:
            if self.embedding_model is None:
                # ä½¿ç”¨æ¨¡æ‹Ÿå‘é‡
                hash_value = hash(text) % (2**32)
                np.random.seed(hash_value)
                vector = np.random.normal(0, 1, self.vector_dimension)
                vector = vector / np.linalg.norm(vector)
                return vector.tolist()
            
            # OpenAIå®¢æˆ·ç«¯ï¼ˆXinferenceï¼‰
            if hasattr(self.embedding_model, 'embeddings'):
                response = self.embedding_model.embeddings.create(
                    input=[text],
                    model="jina-embeddings-v3"
                )
                return response.data[0].embedding
            
            # å…¶ä»–ç±»å‹çš„embeddingæ¨¡å‹
            elif hasattr(self.embedding_model, 'encode'):
                if hasattr(self.embedding_model, 'mdl'):
                    # RAGFlow LLMBundle
                    embeddings, _ = self.embedding_model.encode([text])
                    return embeddings[0]
                else:
                    # sentence-transformers
                    embedding = self.embedding_model.encode(text, normalize_embeddings=True)
                    return embedding.tolist()
            
            else:
                raise Exception("æœªçŸ¥çš„embeddingæ¨¡å‹ç±»å‹")
                
        except Exception as e:
            logger.warning(f"ç”Ÿæˆembeddingå¤±è´¥: {e}ï¼Œä½¿ç”¨æ¨¡æ‹Ÿå‘é‡")
            hash_value = hash(text) % (2**32)
            np.random.seed(hash_value)
            vector = np.random.normal(0, 1, self.vector_dimension)
            vector = vector / np.linalg.norm(vector)
            return vector.tolist()
    
    def create_simple_search(self, query_text):
        """åˆ›å»ºç®€å•æ–‡æœ¬æœç´¢"""
        return [MatchTextExpr(
            fields=["title_tks^10", "title_sm_tks^5", "important_kwd^30", "important_tks^20", "question_tks^20", "content_ltks^2", "content_sm_ltks"],
            matching_text=query_text,
            topn=10
        )]
    
    def create_vector_search(self, query_text):
        """åˆ›å»ºå‘é‡æœç´¢"""
        vector = self.generate_embedding(query_text)
        vector_field = f"q_{self.vector_dimension}_vec"
        return [MatchDenseExpr(
            vector_column_name=vector_field,
            embedding_data=vector,
            embedding_data_type="float",
            distance_type="cosine",
            topn=10
        )]
    
    def create_hybrid_search(self, query_text, vector_weight=0.5):
        """åˆ›å»ºæ··åˆæœç´¢ï¼ˆæ–‡æœ¬+å‘é‡ï¼‰"""
        vector = self.generate_embedding(query_text)
        vector_field = f"q_{self.vector_dimension}_vec"
        
        text_weight = 1.0 - vector_weight
        
        return [
            MatchTextExpr(
                fields=["title_tks^10", "title_sm_tks^5", "important_kwd^30", "important_tks^20", "question_tks^20", "content_ltks^2", "content_sm_ltks"],
                matching_text=query_text,
                topn=10
            ),
            MatchDenseExpr(
                vector_column_name=vector_field,
                embedding_data=vector,
                embedding_data_type="float",
                distance_type="cosine",
                topn=10
            ),
            FusionExpr(
                method="weighted_sum",
                topn=10,
                fusion_params={"weights": f"{text_weight:.3f}, {vector_weight:.3f}"}
            )
        ]
    
    def run_search(self, conn, index_name, kb_ids, match_exprs, search_type=""):
        """æ‰§è¡Œæœç´¢å¹¶è¿”å›ç»“æœ"""
        try:
            start_time = time.time()
            
            results = conn.search(
                selectFields=["id", "title_tks", "content_with_weight"],
                highlightFields=[],
                condition={"available_int": 1},
                matchExprs=match_exprs,
                orderBy=OrderByExpr(),
                offset=0,
                limit=5,
                indexNames=index_name,
                knowledgebaseIds=kb_ids
            )
            
            end_time = time.time()
            search_time = (end_time - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
            
            total_hits = conn.getTotal(results)
            hits = results.get("hits", {}).get("hits", [])
            
            return {
                "total": total_hits,
                "hits": hits,
                "time_ms": search_time,
                "search_type": search_type
            }
            
        except Exception as e:
            logger.error(f"æœç´¢å¤±è´¥ ({search_type}): {e}")
            return {
                "total": 0,
                "hits": [],
                "time_ms": 0,
                "search_type": search_type,
                "error": str(e)
            }
    
    def format_results(self, results, engine_name):
        """æ ¼å¼åŒ–æœç´¢ç»“æœ"""
        if "error" in results:
            return f"âŒ {engine_name} æœç´¢å¤±è´¥: {results['error']}"
        
        output = []
        output.append(f"ğŸ” {engine_name} ({results['search_type']}):")
        output.append(f"   æ€»æ•°: {results['total']}, è€—æ—¶: {results['time_ms']:.1f}ms")
        
        for i, hit in enumerate(results['hits'][:3], 1):
            source = hit.get('_source', {})
            title = source.get('title_tks', 'æ— æ ‡é¢˜')
            content = source.get('content_with_weight', '')[:100]
            output.append(f"   {i}. {title}")
            output.append(f"      {content}...")
        
        return "\n".join(output)
    
    def test_search_query(self, query_text, index_name, kb_ids):
        """æµ‹è¯•å•ä¸ªæŸ¥è¯¢"""
        print(f"\nğŸ” æµ‹è¯•æŸ¥è¯¢: '{query_text}'")
        print("=" * 60)
        
        # 1. æ–‡æœ¬æœç´¢
        print("\nğŸ“ æ–‡æœ¬æœç´¢:")
        text_match_exprs = self.create_simple_search(query_text)
        
        if self.es_conn:
            es_text_results = self.run_search(self.es_conn, index_name, kb_ids, text_match_exprs, "æ–‡æœ¬æœç´¢")
            print(self.format_results(es_text_results, "Elasticsearch"))
        
        if self.pd_conn:
            pd_text_results = self.run_search(self.pd_conn, index_name, kb_ids, text_match_exprs, "æ–‡æœ¬æœç´¢")
            print(self.format_results(pd_text_results, "ParadeDB"))
        
        # 2. å‘é‡æœç´¢
        print(f"\nğŸ¯ å‘é‡æœç´¢:")
        vector_match_exprs = self.create_vector_search(query_text)
        
        if self.es_conn:
            es_vector_results = self.run_search(self.es_conn, index_name, kb_ids, vector_match_exprs, "å‘é‡æœç´¢")
            print(self.format_results(es_vector_results, "Elasticsearch"))
        
        if self.pd_conn:
            pd_vector_results = self.run_search(self.pd_conn, index_name, kb_ids, vector_match_exprs, "å‘é‡æœç´¢")
            print(self.format_results(pd_vector_results, "ParadeDB"))
        
        # 3. æ··åˆæœç´¢
        print(f"\nğŸ”€ æ··åˆæœç´¢ (å‘é‡æƒé‡=0.7):")
        hybrid_match_exprs = self.create_hybrid_search(query_text, vector_weight=0.7)
        
        if self.es_conn:
            es_hybrid_results = self.run_search(self.es_conn, index_name, kb_ids, hybrid_match_exprs, "æ··åˆæœç´¢")
            print(self.format_results(es_hybrid_results, "Elasticsearch"))
        
        if self.pd_conn:
            pd_hybrid_results = self.run_search(self.pd_conn, index_name, kb_ids, hybrid_match_exprs, "æ··åˆæœç´¢")
            print(self.format_results(pd_hybrid_results, "ParadeDB"))

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¿«é€Ÿæœç´¢å¼•æ“å¯¹æ¯”æµ‹è¯•")
    print("=" * 50)
    
    # åˆå§‹åŒ–æµ‹è¯•å™¨
    tester = QuickSearchTester()
    
    # æ£€æŸ¥è¿æ¥çŠ¶æ€
    if not tester.es_conn and not tester.pd_conn:
        print("âŒ æ²¡æœ‰å¯ç”¨çš„æœç´¢å¼•æ“è¿æ¥")
        return
    
    # å°è¯•åŠ è½½æµ‹è¯•é…ç½®
    try:
        from test_kb_config import TEST_CONFIG
        index_name = TEST_CONFIG["index_name"]
        kb_ids = TEST_CONFIG["kb_ids"]
        test_queries = TEST_CONFIG["test_queries"][:5]  # åªæµ‹è¯•å‰5ä¸ªæŸ¥è¯¢
        print(f"âœ… åŠ è½½æµ‹è¯•é…ç½®æˆåŠŸ")
        print(f"   ç´¢å¼•: {index_name}")
        print(f"   çŸ¥è¯†åº“ID: {kb_ids}")
    except ImportError:
        print("âš ï¸ æœªæ‰¾åˆ°test_kb_config.pyï¼Œè¯·å…ˆè¿è¡Œsimple_kb_setup.py")
        return
    
    # æ‰§è¡Œæµ‹è¯•æŸ¥è¯¢
    for query in test_queries:
        tester.test_search_query(query, index_name, kb_ids)
        time.sleep(1)  # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
    
    print(f"\nğŸ‰ æµ‹è¯•å®Œæˆ!")
    print(f"ğŸ’¡ å¦‚éœ€æ›´è¯¦ç»†çš„å¯¹æ¯”åˆ†æï¼Œè¯·è¿è¡Œ: python compare_search_engines.py")

if __name__ == "__main__":
    main() 