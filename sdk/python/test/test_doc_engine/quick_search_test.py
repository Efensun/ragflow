#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¿«é€Ÿæœç´¢å¼•æ“å¯¹æ¯”æµ‹è¯•è„šæœ¬ï¼ˆæ”¯æŒçœŸå®embeddingå‘é‡ï¼‰

è¿™æ˜¯ä¸€ä¸ªç®€åŒ–ç‰ˆæœ¬ï¼Œç”¨äºå¿«é€ŸéªŒè¯ESå’ŒParadeDBçš„åŸºæœ¬æœç´¢åŠŸèƒ½ï¼Œä½¿ç”¨çœŸå®embeddingè¿›è¡Œè¯­ä¹‰æœç´¢æµ‹è¯•
"""

import os
import sys
import time
import logging
from typing import List

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from rag import settings
from rag.utils.es_conn import ESConnection
from rag.utils.pd_conn import PDConnection
from rag.utils.doc_store_conn import MatchTextExpr, MatchDenseExpr, FusionExpr, OrderByExpr
import numpy as np

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class QuickSearchTester:
    """å¿«é€Ÿæœç´¢æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.es_conn = None
        self.pd_conn = None
        self.embedding_model = None
        self.vector_dimension = 1024  # é»˜è®¤å‘é‡ç»´åº¦
        self.init_connections()
        self.init_embedding_model()
    
    def init_connections(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¿æ¥"""
    try:
            # åˆå§‹åŒ–ESè¿æ¥
        if hasattr(settings, 'ES') and settings.ES.get('hosts'):
            print("ğŸ”— è¿æ¥Elasticsearch...")
                self.es_conn = ESConnection()
            print("âœ… ESè¿æ¥æˆåŠŸ")
        else:
            print("âš ï¸ æœªé…ç½®ESï¼Œè·³è¿‡ESæµ‹è¯•")
    except Exception as e:
        print(f"âŒ ESè¿æ¥å¤±è´¥: {e}")
    
    try:
            # åˆå§‹åŒ–ParadeDBè¿æ¥
        if hasattr(settings, 'PARADEDB') and settings.PARADEDB.get('host'):
            print("ğŸ”— è¿æ¥ParadeDB...")
                self.pd_conn = PDConnection()
            print("âœ… ParadeDBè¿æ¥æˆåŠŸ")
        else:
            print("âš ï¸ æœªé…ç½®ParadeDBï¼Œè·³è¿‡ParadeDBæµ‹è¯•")
    except Exception as e:
        print(f"âŒ ParadeDBè¿æ¥å¤±è´¥: {e}")
    
    def init_embedding_model(self):
        """åˆå§‹åŒ–embeddingæ¨¡å‹ï¼ˆä¸simple_kb_setup.pyä¿æŒä¸€è‡´ï¼‰"""
        try:
            # æ–¹æ³•1: ç›´æ¥ä½¿ç”¨OpenAIå®¢æˆ·ç«¯è°ƒç”¨Xinferenceï¼ˆæ¨èï¼Œå·²éªŒè¯å¯ç”¨ï¼‰
            try:
                from openai import OpenAI
                
                # ä½¿ç”¨ç”¨æˆ·æä¾›çš„Xinferenceåœ°å€
                xinference_client = OpenAI(
                    api_key="empty", 
                    base_url="http://120.77.38.66:8008/v1"
                )
                
                # æµ‹è¯•æ¨¡å‹æ˜¯å¦å¯ç”¨
                test_response = xinference_client.embeddings.create(
                    input=["æµ‹è¯•æ–‡æœ¬"],
                    model="jina-embeddings-v3"
                )
                
                if test_response.data and len(test_response.data[0].embedding) > 0:
                    self.embedding_model = xinference_client
                    self.vector_dimension = len(test_response.data[0].embedding)
                    print(f"âœ… ä½¿ç”¨OpenAIå®¢æˆ·ç«¯ç›´æ¥è°ƒç”¨Xinference jina-embeddings-v3æ¨¡å‹ï¼Œå‘é‡ç»´åº¦: {self.vector_dimension}")
                    return
                    
            except Exception as e:
                logger.warning(f"æ— æ³•ä½¿ç”¨OpenAIå®¢æˆ·ç«¯è°ƒç”¨Xinference: {e}")
            
            # æ–¹æ³•2: ä½¿ç”¨ç”¨æˆ·æä¾›çš„ç§Ÿæˆ·IDå’Œembeddingé…ç½®ï¼ˆå¤‡é€‰ï¼‰
            try:
                from api.db.services.llm_service import LLMBundle, LLMType
                
                # ä½¿ç”¨ç”¨æˆ·æä¾›çš„ç§Ÿæˆ·ID
                tenant_id = "c68cf3243ba311f08ca03fb4f23258b9"
                print(f"å°è¯•ä½¿ç”¨ç”¨æˆ·æä¾›çš„ç§Ÿæˆ·ID: {tenant_id}")
                
                # å°è¯•åˆ›å»ºembeddingæ¨¡å‹ï¼ˆä½¿ç”¨é…ç½®çš„jina-embeddings-v3@Xinferenceï¼‰
                try:
                    embedding_bundle = LLMBundle(tenant_id, LLMType.EMBEDDING.value)
                    
                    # æµ‹è¯•æ¨¡å‹æ˜¯å¦å¯ç”¨
                    test_embeddings, _ = embedding_bundle.encode(["æµ‹è¯•æ–‡æœ¬"])
                    if test_embeddings and len(test_embeddings[0]) > 0:
                        self.embedding_model = embedding_bundle
                        self.vector_dimension = len(test_embeddings[0])
                        print(f"âœ… ä½¿ç”¨RAGFlowé…ç½®çš„jina-embeddings-v3æ¨¡å‹ï¼Œå‘é‡ç»´åº¦: {self.vector_dimension}")
                        return
                except Exception as e:
                    logger.warning(f"æ— æ³•ä½¿ç”¨RAGFlow LLMBundle: {e}")
                    
            except Exception as e:
                logger.warning(f"æ— æ³•å¯¼å…¥RAGFlow LLMBundle: {e}")
            
            # æ–¹æ³•3: å°è¯•ä½¿ç”¨RAGFlowçš„XinferenceEmbedç±»ï¼ˆå¤‡é€‰ï¼‰
            try:
                from rag.llm.embedding_model import XinferenceEmbed
                
                xinference_embed = XinferenceEmbed(
                    key="",  # Xinferenceé€šå¸¸ä¸éœ€è¦API key
                    model_name="jina-embeddings-v3",
                    base_url="http://120.77.38.66:8008/"
                )
                
                # æµ‹è¯•embedding
                test_embeddings, tokens = xinference_embed.encode(["æµ‹è¯•æ–‡æœ¬"])
                if test_embeddings and len(test_embeddings[0]) > 0:
                    self.embedding_model = xinference_embed
                    self.vector_dimension = len(test_embeddings[0])
                    print(f"âœ… ä½¿ç”¨RAGFlow XinferenceEmbedæ¨¡å‹ï¼Œå‘é‡ç»´åº¦: {self.vector_dimension}")
                    return
                    
            except Exception as e:
                logger.warning(f"æ— æ³•ä½¿ç”¨RAGFlow XinferenceEmbed: {e}")
            
            # æ–¹æ³•4: å°è¯•ç›´æ¥ä½¿ç”¨RAGFlowçš„embeddingæ¨¡å‹ç±»
            try:
                from rag.llm import EmbeddingModel
                
                # å°è¯•ä½¿ç”¨jina-embeddings-v3æ¨¡å‹
                if "Xinference" in EmbeddingModel:
                    try:
                        # å‡è®¾jina-embeddings-v3é€šè¿‡Xinferenceæä¾›
                        xinference_embed = EmbeddingModel["Xinference"](
                            api_key="", 
                            model_name="jina-embeddings-v3",
                            base_url="http://120.77.38.66:8008/"
                        )
                        test_embeddings, _ = xinference_embed.encode(["æµ‹è¯•æ–‡æœ¬"])
                        if test_embeddings and len(test_embeddings[0]) > 0:
                            self.embedding_model = xinference_embed
                            self.vector_dimension = len(test_embeddings[0])
                            print(f"âœ… ä½¿ç”¨Xinference jina-embeddings-v3æ¨¡å‹ï¼Œå‘é‡ç»´åº¦: {self.vector_dimension}")
                            return
                    except Exception as e:
                        logger.warning(f"æ— æ³•ä½¿ç”¨Xinference jina-embeddings-v3: {e}")
                
                # å°è¯•ä½¿ç”¨BAAIæ¨¡å‹
                if "BAAI" in EmbeddingModel:
                    try:
                        baai_embed = EmbeddingModel["BAAI"](
                            api_key="", 
                            model_name="BAAI/bge-large-zh-v1.5"
                        )
                        test_embeddings, _ = baai_embed.encode(["æµ‹è¯•æ–‡æœ¬"])
                        if test_embeddings and len(test_embeddings[0]) > 0:
                            self.embedding_model = baai_embed
                            self.vector_dimension = len(test_embeddings[0])
                            print(f"âœ… ä½¿ç”¨BAAI embeddingæ¨¡å‹ï¼Œå‘é‡ç»´åº¦: {self.vector_dimension}")
                            return
                    except Exception as e:
                        logger.warning(f"æ— æ³•ä½¿ç”¨BAAI embeddingæ¨¡å‹: {e}")
                        
            except Exception as e:
                logger.warning(f"æ— æ³•åŠ è½½RAGFlow embeddingæ¨¡å‹: {e}")
            
            # æ–¹æ³•5: å¤‡é€‰æ–¹æ¡ˆ - ä½¿ç”¨sentence-transformers
            try:
                from sentence_transformers import SentenceTransformer
                
                # ä¼˜å…ˆå°è¯•jina-embeddings-v3
                try:
                    self.embedding_model = SentenceTransformer('jinaai/jina-embeddings-v3')
                    test_embedding = self.embedding_model.encode("æµ‹è¯•æ–‡æœ¬", normalize_embeddings=True)
                    self.vector_dimension = len(test_embedding)
                    print(f"âœ… ä½¿ç”¨sentence-transformers jina-embeddings-v3æ¨¡å‹ï¼Œå‘é‡ç»´åº¦: {self.vector_dimension}")
                    return
                except Exception as e:
                    logger.warning(f"æ— æ³•åŠ è½½jina-embeddings-v3: {e}")
                
                # å¤‡é€‰BAAIæ¨¡å‹
                model_name = 'BAAI/bge-large-zh-v1.5'
                self.embedding_model = SentenceTransformer(model_name)
                test_embedding = self.embedding_model.encode("æµ‹è¯•æ–‡æœ¬", normalize_embeddings=True)
                self.vector_dimension = len(test_embedding)
                print(f"âœ… ä½¿ç”¨sentence-transformersæ¨¡å‹: {model_name}ï¼Œå‘é‡ç»´åº¦: {self.vector_dimension}")
                return
            except ImportError:
                logger.warning("sentence-transformersæœªå®‰è£…ï¼Œå»ºè®®å®‰è£…: pip install sentence-transformers")
            except Exception as e:
                logger.warning(f"æ— æ³•åŠ è½½sentence-transformersæ¨¡å‹: {e}")
            
            # æ–¹æ³•6: å¤‡é€‰æ–¹æ¡ˆ - ä½¿ç”¨transformers
            try:
                from transformers import AutoTokenizer, AutoModel
                import torch
                
                # ä¼˜å…ˆå°è¯•jina-embeddings-v3
                try:
                    model_name = 'jinaai/jina-embeddings-v3'
                    self.tokenizer = AutoTokenizer.from_pretrained(model_name)
                    self.model = AutoModel.from_pretrained(model_name)
                    self.embedding_model = "transformers"
                    
                    # æµ‹è¯•è·å–å‘é‡ç»´åº¦
                    inputs = self.tokenizer("æµ‹è¯•æ–‡æœ¬", return_tensors='pt', truncation=True, max_length=512)
                    with torch.no_grad():
                        outputs = self.model(**inputs)
                        embedding = outputs.last_hidden_state[:, 0, :].squeeze()
                        self.vector_dimension = len(embedding)
                    
                    print(f"âœ… ä½¿ç”¨transformers jina-embeddings-v3æ¨¡å‹ï¼Œå‘é‡ç»´åº¦: {self.vector_dimension}")
                    return
                except Exception as e:
                    logger.warning(f"æ— æ³•åŠ è½½transformers jina-embeddings-v3: {e}")
                
                # å¤‡é€‰BAAIæ¨¡å‹
                model_name = 'BAAI/bge-large-zh-v1.5'
                self.tokenizer = AutoTokenizer.from_pretrained(model_name)
                self.model = AutoModel.from_pretrained(model_name)
                self.embedding_model = "transformers"
                
                # æµ‹è¯•è·å–å‘é‡ç»´åº¦
                inputs = self.tokenizer("æµ‹è¯•æ–‡æœ¬", return_tensors='pt', truncation=True, max_length=512)
                with torch.no_grad():
                    outputs = self.model(**inputs)
                    embedding = outputs.last_hidden_state[:, 0, :].squeeze()
                    self.vector_dimension = len(embedding)
                
                print(f"âœ… ä½¿ç”¨transformersæ¨¡å‹: {model_name}ï¼Œå‘é‡ç»´åº¦: {self.vector_dimension}")
                return
            except ImportError:
                logger.warning("transformersæœªå®‰è£…ï¼Œå»ºè®®å®‰è£…: pip install transformers torch")
            except Exception as e:
                logger.warning(f"æ— æ³•åŠ è½½transformersæ¨¡å‹: {e}")
    
            # å¦‚æœæ‰€æœ‰æ–¹æ¡ˆéƒ½å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿå‘é‡
            print("âš ï¸ æ— æ³•åŠ è½½ä»»ä½•embeddingæ¨¡å‹ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿå‘é‡")
            print("âš ï¸ å»ºè®®å®‰è£…: pip install sentence-transformers")
            print("âš ï¸ æˆ–é…ç½®RAGFlowçš„embeddingæ¨¡å‹")
            self.embedding_model = None
            self.vector_dimension = 1024  # jina-embeddings-v3çš„å‘é‡ç»´åº¦
            
        except Exception as e:
            logger.error(f"âŒ embeddingæ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            self.embedding_model = None
            self.vector_dimension = 1024  # jina-embeddings-v3çš„å‘é‡ç»´åº¦
    
    def generate_embedding(self, text: str) -> List[float]:
        """ç”Ÿæˆæ–‡æœ¬çš„embeddingå‘é‡ï¼ˆä¸simple_kb_setup.pyä¿æŒä¸€è‡´ï¼‰"""
        try:
            if self.embedding_model is None:
                # ä½¿ç”¨æ¨¡æ‹Ÿå‘é‡ä½œä¸ºå¤‡é€‰
                hash_value = hash(text) % (2**32)
                np.random.seed(hash_value)
                vector = np.random.normal(0, 1, self.vector_dimension)
                vector = vector / np.linalg.norm(vector)
                return vector.tolist()
            
            # OpenAIå®¢æˆ·ç«¯ï¼ˆXinferenceï¼‰
            if hasattr(self.embedding_model, 'embeddings'):
                response = self.embedding_model.embeddings.create(
                    input=[text],
                    model="jina-embeddings-v3"
                )
                return response.data[0].embedding
            
            # RAGFlow LLMBundle
            elif hasattr(self.embedding_model, 'encode') and hasattr(self.embedding_model, 'mdl'):
                embeddings, _ = self.embedding_model.encode([text])
                return embeddings[0]
            
            # RAGFlow embeddingæ¨¡å‹ç±»
            elif hasattr(self.embedding_model, 'encode') and not hasattr(self.embedding_model, 'mdl'):
                embeddings, _ = self.embedding_model.encode([text])
                return embeddings[0]
            
            # sentence-transformers
            elif hasattr(self.embedding_model, 'encode'):
                embedding = self.embedding_model.encode(text, normalize_embeddings=True)
                return embedding.tolist()
            
            # transformersæ¨¡å‹
            elif self.embedding_model == "transformers":
                import torch
                inputs = self.tokenizer(text, return_tensors='pt', truncation=True, max_length=512)
                with torch.no_grad():
                    outputs = self.model(**inputs)
                    # ä½¿ç”¨[CLS] tokençš„embedding
                    embedding = outputs.last_hidden_state[:, 0, :].squeeze()
                    # å½’ä¸€åŒ–
                    embedding = embedding / torch.norm(embedding)
                    return embedding.numpy().tolist()
            
            else:
                raise Exception("æœªçŸ¥çš„embeddingæ¨¡å‹ç±»å‹")
                
        except Exception as e:
            logger.warning(f"ç”Ÿæˆembeddingå¤±è´¥: {e}ï¼Œä½¿ç”¨æ¨¡æ‹Ÿå‘é‡")
            # ä½¿ç”¨æ–‡æœ¬hashä½œä¸ºç§å­ï¼Œç¡®ä¿ç›¸åŒæ–‡æœ¬ç”Ÿæˆç›¸åŒå‘é‡
            hash_value = hash(text) % (2**32)
            np.random.seed(hash_value)
            vector = np.random.normal(0, 1, self.vector_dimension)
            vector = vector / np.linalg.norm(vector)
            return vector.tolist()
    
    def create_simple_search(self, query_text):
        """åˆ›å»ºç®€å•çš„æ–‡æœ¬æœç´¢è¡¨è¾¾å¼"""
        return [MatchTextExpr(
            fields=["content_ltks^10", "title_tks^8", "content_with_weight^2"],
            matching_text=query_text,
            topn=10,
            extra_options={"minimum_should_match": 0.3}
        )]
    
    def create_vector_search(self, query_text):
        """åˆ›å»ºå‘é‡æœç´¢è¡¨è¾¾å¼ï¼ˆä½¿ç”¨çœŸå®embeddingï¼‰"""
        # ç”ŸæˆæŸ¥è¯¢å‘é‡
        query_vector = self.generate_embedding(query_text)
        print(f"  æŸ¥è¯¢å‘é‡ç»´åº¦: {len(query_vector)}")
        
        # åŠ¨æ€ç”Ÿæˆå‘é‡å­—æ®µå
        vector_field_name = f"q_{self.vector_dimension}_vec"
        
        return [MatchDenseExpr(
            vector_column_name=vector_field_name,
            embedding_data=query_vector,
            topn=10,
            extra_options={"similarity": 0.1}
        )]
    
    def create_hybrid_search(self, query_text, vector_weight=0.5):
        """åˆ›å»ºæ··åˆæœç´¢è¡¨è¾¾å¼ï¼ˆæ–‡æœ¬+çœŸå®å‘é‡ï¼‰"""
        expressions = []
        
        # æ–‡æœ¬æœç´¢
        text_expr = MatchTextExpr(
            fields=["content_ltks^10", "title_tks^8", "content_with_weight^2"],
            matching_text=query_text,
            topn=10,
            extra_options={"minimum_should_match": 0.3}
        )
        expressions.append(text_expr)
        
        # å‘é‡æœç´¢ï¼ˆä½¿ç”¨çœŸå®embeddingï¼‰
        query_vector = self.generate_embedding(query_text)
        vector_field_name = f"q_{self.vector_dimension}_vec"
        vector_expr = MatchDenseExpr(
            vector_column_name=vector_field_name,
            embedding_data=query_vector,
            topn=10,
            extra_options={"similarity": 0.1}
        )
        expressions.append(vector_expr)
        
        # èåˆè¡¨è¾¾å¼
        text_weight = 1.0 - vector_weight
        fusion_expr = FusionExpr(
            method="weighted_sum",
            topn=10,
            fusion_params={"weights": f"{text_weight}, {vector_weight}"}
        )
        expressions.append(fusion_expr)
        
        return expressions

def test_basic_search():
    """æµ‹è¯•åŸºæœ¬æœç´¢åŠŸèƒ½"""
    print("ğŸ” å¿«é€Ÿæœç´¢å¼•æ“å¯¹æ¯”æµ‹è¯•ï¼ˆä½¿ç”¨çœŸå®embeddingå‘é‡ï¼‰")
    print("=" * 60)
    
    # å°è¯•åŠ è½½è‡ªåŠ¨ç”Ÿæˆçš„é…ç½®
    try:
        from test_kb_config import TEST_CONFIG
        INDEX_NAME = TEST_CONFIG["index_name"]
        KB_IDS = TEST_CONFIG["kb_ids"]
        TEST_QUERIES = TEST_CONFIG["test_queries"][:3]  # ä½¿ç”¨å‰3ä¸ªæµ‹è¯•æŸ¥è¯¢
        print("âœ… ä½¿ç”¨è‡ªåŠ¨ç”Ÿæˆçš„é…ç½®")
    except ImportError:
        # å¦‚æœæ²¡æœ‰é…ç½®æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤å€¼
        print("âš ï¸ æœªæ‰¾åˆ°test_kb_config.pyï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        print("ğŸ’¡ å»ºè®®å…ˆè¿è¡Œ python simple_kb_setup.py åˆ›å»ºæµ‹è¯•æ•°æ®")
        INDEX_NAME = "ragflow_6a2a5a8c00a611f0883a0242ac140006"
        KB_IDS = ["6a2a5a8c-00a6-11f0-883a-0242ac140006"]
        TEST_QUERIES = ["äººå·¥æ™ºèƒ½", "æœºå™¨å­¦ä¹ ", "è‡ªç„¶è¯­è¨€å¤„ç†"]
    
    print(f"ç´¢å¼•åç§°: {INDEX_NAME}")
    print(f"çŸ¥è¯†åº“ID: {KB_IDS}")
    print(f"æµ‹è¯•æŸ¥è¯¢: {TEST_QUERIES}")
    print()
    
    # åˆå§‹åŒ–æµ‹è¯•å™¨
    tester = QuickSearchTester()
    
    if not tester.es_conn and not tester.pd_conn:
        print("âŒ æ²¡æœ‰å¯ç”¨çš„æœç´¢å¼•æ“è¿æ¥")
        return
    
    print(f"Embeddingæ¨¡å‹: {type(tester.embedding_model).__name__ if tester.embedding_model else 'simulated'}")
    print()
    
    # æµ‹è¯•æ¯ä¸ªæŸ¥è¯¢
    for query_idx, test_query in enumerate(TEST_QUERIES):
        print(f"ğŸ§ª æµ‹è¯•æŸ¥è¯¢ {query_idx + 1}/{len(TEST_QUERIES)}: '{test_query}'")
        print("=" * 50)
    
    # æµ‹è¯•ä¸åŒçš„æœç´¢æ–¹å¼
    test_cases = [
            ("çº¯æ–‡æœ¬æœç´¢", tester.create_simple_search(test_query)),
            ("çº¯å‘é‡æœç´¢", tester.create_vector_search(test_query)),
            ("æ··åˆæœç´¢(0.5)", tester.create_hybrid_search(test_query, 0.5))
    ]
    
    for test_name, match_exprs in test_cases:
            print(f"\nğŸ” {test_name}")
        print("-" * 30)
        
        # ESæœç´¢
            if tester.es_conn:
            try:
                start_time = time.time()
                    es_res = tester.es_conn.search(
                        selectFields=["id", "title_tks", "content_with_weight"],
                    highlightFields=[],
                    condition={"available_int": 1},
                    matchExprs=match_exprs,
                    orderBy=OrderByExpr(),
                    offset=0,
                    limit=5,
                    indexNames=INDEX_NAME,
                    knowledgebaseIds=KB_IDS
                )
                es_time = time.time() - start_time
                
                es_hits = es_res.get("hits", {}).get("hits", [])
                print(f"ESç»“æœ: {len(es_hits)}æ¡, è€—æ—¶{es_time:.3f}ç§’")
                
                for i, hit in enumerate(es_hits[:3]):
                        source = hit.get("_source", {})
                        title = source.get("title_tks", "")
                    score = hit.get("_score", 0)
                        print(f"  {i+1}. {title} (åˆ†æ•°: {score:.3f})")
                    
            except Exception as e:
                print(f"ESæœç´¢å¤±è´¥: {e}")
        
        # ParadeDBæœç´¢
            if tester.pd_conn:
            try:
                start_time = time.time()
                    pd_res = tester.pd_conn.search(
                        selectFields=["id", "title_tks", "content_with_weight"],
                    highlightFields=[],
                    condition={"available_int": 1},
                    matchExprs=match_exprs,
                    orderBy=OrderByExpr(),
                    offset=0,
                    limit=5,
                    indexNames=INDEX_NAME,
                    knowledgebaseIds=KB_IDS
                )
                pd_time = time.time() - start_time
                
                pd_hits = pd_res.get("hits", {}).get("hits", [])
                print(f"ParadeDBç»“æœ: {len(pd_hits)}æ¡, è€—æ—¶{pd_time:.3f}ç§’")
                
                for i, hit in enumerate(pd_hits[:3]):
                        source = hit.get("_source", {})
                        title = source.get("title_tks", "")
                    score = hit.get("_score", 0)
                        print(f"  {i+1}. {title} (åˆ†æ•°: {score:.3f})")
                    
            except Exception as e:
                print(f"ParadeDBæœç´¢å¤±è´¥: {e}")
        
        # ç®€å•å¯¹æ¯”
            if tester.es_conn and tester.pd_conn:
            try:
                es_hits = es_res.get("hits", {}).get("hits", [])
                pd_hits = pd_res.get("hits", {}).get("hits", [])
                
                    if es_hits and pd_hits:
                        # æå–æ–‡æ¡£IDè¿›è¡Œå¯¹æ¯”
                        es_ids = [hit.get("_id") for hit in es_hits]
                        pd_ids = [hit.get("_id") for hit in pd_hits]
                        
                        # è®¡ç®—é‡å 
                        common_ids = set(es_ids) & set(pd_ids)
                        overlap_ratio = len(common_ids) / max(len(es_ids), len(pd_ids)) if max(len(es_ids), len(pd_ids)) > 0 else 0
                
                        print(f"ğŸ“Š ç»“æœå¯¹æ¯”: é‡å ç‡ {overlap_ratio:.2%} ({len(common_ids)}/{max(len(es_ids), len(pd_ids))})")
                
            except Exception as e:
                    print(f"ç»“æœå¯¹æ¯”å¤±è´¥: {e}")
        
        print()  # æŸ¥è¯¢é—´çš„åˆ†éš”
    
    print("ğŸ‰ å¿«é€Ÿæµ‹è¯•å®Œæˆ!")
    print("ğŸ’¡ å¦‚éœ€è¯¦ç»†åˆ†æï¼Œè¯·è¿è¡Œ: python compare_search_engines.py")

def main():
    """ä¸»å‡½æ•°"""
    try:
        test_basic_search()
        print("âœ… å¿«é€Ÿæµ‹è¯•å®Œæˆ")
        print("\nğŸ’¡ æç¤º: å¦‚éœ€è¯¦ç»†åˆ†æï¼Œè¯·ä½¿ç”¨ compare_search_engines.py")
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 