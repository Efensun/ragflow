#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ESå’ŒParadeDBæœç´¢ç»“æœå¯¹æ¯”éªŒè¯è„šæœ¬

è¯¥è„šæœ¬ç”¨äºéªŒè¯åœ¨ç›¸åŒé…ç½®ä¸‹ï¼ŒESå’ŒParadeDBæ˜¯å¦èƒ½å¬å›å¤§è‡´ç›¸åŒé¡ºåºçš„æ–‡æ¡£å—ï¼Œ
ä»¥åŠç›¸ä¼¼åº¦çš„ä¸€è‡´æ€§ã€‚

ä¸»è¦åŠŸèƒ½ï¼š
1. ä½¿ç”¨ç›¸åŒçš„æŸ¥è¯¢å‚æ•°åˆ†åˆ«è°ƒç”¨ESå’ŒParadeDB
2. æ¯”è¾ƒè¿”å›ç»“æœçš„æ–‡æ¡£IDé¡ºåº
3. åˆ†æç›¸ä¼¼åº¦åˆ†æ•°çš„å·®å¼‚
4. ç”Ÿæˆè¯¦ç»†çš„å¯¹æ¯”æŠ¥å‘Š
"""

import os
import sys
import json
import time
import logging
import numpy as np
from typing import List, Dict, Any, Tuple
from dataclasses import dataclass
from collections import defaultdict

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from rag import settings
from rag.utils.es_conn import ESConnection
from rag.utils.pd_conn import PDConnection
from rag.utils.doc_store_conn import MatchTextExpr, MatchDenseExpr, FusionExpr, OrderByExpr
from rag.nlp import rag_tokenizer
import hashlib

# å¯¼å…¥é…ç½®
try:
    from search_comparison_config import get_config, validate_config
    CONFIG = get_config()
except ImportError:
    print("âš ï¸ æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶ search_comparison_config.pyï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
    CONFIG = None

# é…ç½®æ—¥å¿—
log_config = CONFIG['logging'] if CONFIG else {'level': 'INFO', 'format': '%(asctime)s - %(name)s - %(levelname)s - %(message)s'}
logging.basicConfig(
    level=getattr(logging, log_config['level']),
    format=log_config['format']
)
logger = logging.getLogger(__name__)

@dataclass
class SearchResult:
    """æœç´¢ç»“æœæ•°æ®ç»“æ„"""
    doc_id: str
    score: float
    content_preview: str
    source: str  # 'es' or 'paradedb'
    rank: int

@dataclass
class ComparisonMetrics:
    """æ¯”è¾ƒæŒ‡æ ‡"""
    total_es_results: int
    total_pd_results: int
    common_docs: int
    rank_correlation: float
    score_correlation: float
    avg_score_diff: float
    top_k_overlap: Dict[int, float]  # k -> overlap_ratio

class SearchEngineComparator:
    """æœç´¢å¼•æ“æ¯”è¾ƒå™¨"""
    
    def __init__(self):
        self.es_conn = None
        self.pd_conn = None
        self.vector_dimension = 1024  # é»˜è®¤å‘é‡ç»´åº¦
        self.init_connections()
        self.detect_vector_dimension()
    
    def init_connections(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¿æ¥"""
        try:
            # åˆå§‹åŒ–ESè¿æ¥
            if hasattr(settings, 'ES') and settings.ES.get('hosts'):
                logger.info("åˆå§‹åŒ–Elasticsearchè¿æ¥...")
                self.es_conn = ESConnection()
                logger.info("âœ… Elasticsearchè¿æ¥æˆåŠŸ")
            else:
                logger.warning("âš ï¸ æœªé…ç½®Elasticsearchï¼Œè·³è¿‡ESæµ‹è¯•")
            
            # åˆå§‹åŒ–ParadeDBè¿æ¥
            if hasattr(settings, 'PARADEDB') and settings.PARADEDB.get('host'):
                logger.info("åˆå§‹åŒ–ParadeDBè¿æ¥...")
                self.pd_conn = PDConnection()
                logger.info("âœ… ParadeDBè¿æ¥æˆåŠŸ")
            else:
                logger.warning("âš ï¸ æœªé…ç½®ParadeDBï¼Œè·³è¿‡ParadeDBæµ‹è¯•")
                
        except Exception as e:
            logger.error(f"âŒ åˆå§‹åŒ–æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            raise
    
    def detect_vector_dimension(self):
        """è‡ªåŠ¨æ£€æµ‹å‘é‡ç»´åº¦"""
        try:
            # å°è¯•ä»é…ç½®æ–‡ä»¶ä¸­è·å–å‘é‡ç»´åº¦
            try:
                from test_kb_config import TEST_CONFIG
                # ä»æµ‹è¯•é…ç½®ä¸­è·å–ä¸€ä¸ªæ ·æœ¬æ–‡æ¡£çš„å‘é‡ç»´åº¦
                index_name = TEST_CONFIG["index_name"]
                kb_ids = TEST_CONFIG["kb_ids"]
                
                # å°è¯•ä»ESè·å–æ ·æœ¬æ–‡æ¡£
                if self.es_conn:
                    from rag.utils.doc_store_conn import OrderByExpr
                    res = self.es_conn.search(
                        selectFields=["metadata"],
                        highlightFields=[],
                        condition={"available_int": 1},
                        matchExprs=[],
                        orderBy=OrderByExpr(),
                        offset=0,
                        limit=1,
                        indexNames=index_name,
                        knowledgebaseIds=kb_ids
                    )
                    hits = res.get("hits", {}).get("hits", [])
                    if hits:
                        metadata = hits[0].get("_source", {}).get("metadata", {})
                        if "vector_dimension" in metadata:
                            self.vector_dimension = metadata["vector_dimension"]
                            logger.info(f"âœ… ä»ESæ ·æœ¬æ–‡æ¡£æ£€æµ‹åˆ°å‘é‡ç»´åº¦: {self.vector_dimension}")
                            return
                
                # å¦‚æœESæ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•ä»ParadeDBè·å–
                if self.pd_conn:
                    from rag.utils.doc_store_conn import OrderByExpr
                    res = self.pd_conn.search(
                        selectFields=["metadata"],
                        highlightFields=[],
                        condition={"available_int": 1},
                        matchExprs=[],
                        orderBy=OrderByExpr(),
                        offset=0,
                        limit=1,
                        indexNames=index_name,
                        knowledgebaseIds=kb_ids
                    )
                    hits = res.get("hits", {}).get("hits", [])
                    if hits:
                        metadata = hits[0].get("_source", {}).get("metadata", {})
                        if "vector_dimension" in metadata:
                            self.vector_dimension = metadata["vector_dimension"]
                            logger.info(f"âœ… ä»ParadeDBæ ·æœ¬æ–‡æ¡£æ£€æµ‹åˆ°å‘é‡ç»´åº¦: {self.vector_dimension}")
                            return
                            
            except ImportError:
                logger.info("æœªæ‰¾åˆ°test_kb_config.pyï¼Œä½¿ç”¨é»˜è®¤å‘é‡ç»´åº¦")
            except Exception as e:
                logger.warning(f"ä»é…ç½®æ–‡ä»¶æ£€æµ‹å‘é‡ç»´åº¦å¤±è´¥: {e}")
            
            logger.info(f"ä½¿ç”¨é»˜è®¤å‘é‡ç»´åº¦: {self.vector_dimension}")
            
        except Exception as e:
            logger.warning(f"å‘é‡ç»´åº¦æ£€æµ‹å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤å€¼: {self.vector_dimension}")
    
    def generate_test_vector(self, dimension: int = 1024) -> List[float]:
        """ç”Ÿæˆæµ‹è¯•å‘é‡"""
        # ä½¿ç”¨å›ºå®šç§å­ç¡®ä¿å¯é‡å¤æ€§
        np.random.seed(42)
        vector = np.random.normal(0, 1, dimension)
        # å½’ä¸€åŒ–å‘é‡
        vector = vector / np.linalg.norm(vector)
        return vector.tolist()
    
    def create_search_expressions(self, query_text: str, vector_dim: int = 1024, 
                                vector_weight: float = 0.5) -> List:
        """åˆ›å»ºæœç´¢è¡¨è¾¾å¼"""
        expressions = []
        
        # æ–‡æœ¬æœç´¢è¡¨è¾¾å¼ - ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„å­—æ®µè®¾ç½®
        if CONFIG and 'test' in CONFIG and 'search_fields' in CONFIG['test']:
            text_fields = CONFIG['test']['search_fields']
        else:
            text_fields = [
                "content_ltks^10",
                "content_sm_ltks^5", 
                "title_tks^8",
                "title_sm_tks^4",
                "important_tks^6",
                "question_tks^3",
                "content_with_weight^2"
            ]
        
        match_text = MatchTextExpr(
            fields=text_fields,
            matching_text=query_text,
            topn=50,
            extra_options={"minimum_should_match": 0.3}
        )
        expressions.append(match_text)
        
        # å‘é‡æœç´¢è¡¨è¾¾å¼
        test_vector = self.generate_test_vector(vector_dim)
        match_dense = MatchDenseExpr(
            vector_column_name=f"q_{vector_dim}_vec",
            embedding_data=test_vector,
            topn=50,
            extra_options={"similarity": 0.1}
        )
        expressions.append(match_dense)
        
        # èåˆè¡¨è¾¾å¼
        fusion_expr = FusionExpr(
            method="weighted_sum",
            topn=50,
            fusion_params={
                "weights": f"{1.0 - vector_weight}, {vector_weight}"
            }
        )
        expressions.append(fusion_expr)
        
        return expressions
    
    def search_with_engine(self, engine_name: str, conn, index_name: str, 
                          kb_ids: List[str], query_text: str, 
                          vector_weight: float = 0.5, limit: int = 20) -> List[SearchResult]:
        """ä½¿ç”¨æŒ‡å®šå¼•æ“è¿›è¡Œæœç´¢"""
        try:
            # åˆ›å»ºæœç´¢è¡¨è¾¾å¼ï¼Œä½¿ç”¨æ£€æµ‹åˆ°çš„å‘é‡ç»´åº¦
            match_exprs = self.create_search_expressions(query_text, self.vector_dimension, vector_weight)
            
            # æœç´¢å‚æ•° - ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„è®¾ç½®
            if CONFIG and 'test' in CONFIG:
                select_fields = CONFIG['test'].get('select_fields', ["id", "content_with_weight", "title_tks", "docnm_kwd"])
                highlight_fields = CONFIG['test'].get('highlight_fields', ["content_ltks", "title_tks"])
            else:
                select_fields = ["id", "content_with_weight", "title_tks", "docnm_kwd"]
                highlight_fields = ["content_ltks", "title_tks"]
            condition = {"available_int": 1}
            order_by = OrderByExpr()
            
            # æ‰§è¡Œæœç´¢
            start_time = time.time()
            res = conn.search(
                selectFields=select_fields,
                highlightFields=highlight_fields,
                condition=condition,
                matchExprs=match_exprs,
                orderBy=order_by,
                offset=0,
                limit=limit,
                indexNames=index_name,
                knowledgebaseIds=kb_ids
            )
            search_time = time.time() - start_time
            
            # è§£æç»“æœ
            results = []
            hits = res.get("hits", {}).get("hits", [])
            
            for rank, hit in enumerate(hits):
                doc_id = hit.get("_id", "")
                score = hit.get("_score", 0.0)
                source_data = hit.get("_source", {})
                
                # è·å–å†…å®¹é¢„è§ˆ
                content = source_data.get("content_with_weight", "")
                if len(content) > 100:
                    content = content[:100] + "..."
                
                result = SearchResult(
                    doc_id=doc_id,
                    score=float(score),
                    content_preview=content,
                    source=engine_name,
                    rank=rank + 1
                )
                results.append(result)
            
            logger.info(f"{engine_name}æœç´¢å®Œæˆ: {len(results)}æ¡ç»“æœ, è€—æ—¶{search_time:.3f}ç§’")
            return results
            
        except Exception as e:
            logger.error(f"âŒ {engine_name}æœç´¢å¤±è´¥: {e}")
            return []
    
    def calculate_rank_correlation(self, es_results: List[SearchResult], 
                                 pd_results: List[SearchResult]) -> float:
        """è®¡ç®—æ’åç›¸å…³æ€§ï¼ˆSpearmanç›¸å…³ç³»æ•°ï¼‰"""
        # è·å–å…±åŒæ–‡æ¡£
        es_docs = {r.doc_id: r.rank for r in es_results}
        pd_docs = {r.doc_id: r.rank for r in pd_results}
        
        common_docs = set(es_docs.keys()) & set(pd_docs.keys())
        
        if len(common_docs) < 2:
            return 0.0
        
        # æå–æ’å
        es_ranks = [es_docs[doc_id] for doc_id in common_docs]
        pd_ranks = [pd_docs[doc_id] for doc_id in common_docs]
        
        # è®¡ç®—Spearmanç›¸å…³ç³»æ•°
        try:
            correlation = np.corrcoef(es_ranks, pd_ranks)[0, 1]
            return correlation if not np.isnan(correlation) else 0.0
        except:
            return 0.0
    
    def calculate_score_correlation(self, es_results: List[SearchResult], 
                                  pd_results: List[SearchResult]) -> Tuple[float, float]:
        """è®¡ç®—åˆ†æ•°ç›¸å…³æ€§å’Œå¹³å‡å·®å¼‚"""
        # è·å–å…±åŒæ–‡æ¡£çš„åˆ†æ•°
        es_scores = {r.doc_id: r.score for r in es_results}
        pd_scores = {r.doc_id: r.score for r in pd_results}
        
        common_docs = set(es_scores.keys()) & set(pd_scores.keys())
        
        if len(common_docs) < 2:
            return 0.0, 0.0
        
        es_score_list = [es_scores[doc_id] for doc_id in common_docs]
        pd_score_list = [pd_scores[doc_id] for doc_id in common_docs]
        
        # è®¡ç®—ç›¸å…³æ€§
        try:
            correlation = np.corrcoef(es_score_list, pd_score_list)[0, 1]
            correlation = correlation if not np.isnan(correlation) else 0.0
        except:
            correlation = 0.0
        
        # è®¡ç®—å¹³å‡å·®å¼‚
        score_diffs = [abs(es_scores[doc_id] - pd_scores[doc_id]) for doc_id in common_docs]
        avg_diff = np.mean(score_diffs) if score_diffs else 0.0
        
        return correlation, avg_diff
    
    def calculate_top_k_overlap(self, es_results: List[SearchResult], 
                               pd_results: List[SearchResult]) -> Dict[int, float]:
        """è®¡ç®—Top-Ké‡å ç‡"""
        overlaps = {}
        
        for k in [1, 3, 5, 10, 20]:
            if k > min(len(es_results), len(pd_results)):
                continue
                
            es_top_k = set(r.doc_id for r in es_results[:k])
            pd_top_k = set(r.doc_id for r in pd_results[:k])
            
            overlap = len(es_top_k & pd_top_k)
            overlap_ratio = overlap / k
            overlaps[k] = overlap_ratio
        
        return overlaps
    
    def compare_search_results(self, es_results: List[SearchResult], 
                             pd_results: List[SearchResult]) -> ComparisonMetrics:
        """æ¯”è¾ƒæœç´¢ç»“æœ"""
        # åŸºæœ¬ç»Ÿè®¡
        total_es = len(es_results)
        total_pd = len(pd_results)
        
        es_doc_ids = set(r.doc_id for r in es_results)
        pd_doc_ids = set(r.doc_id for r in pd_results)
        common_docs = len(es_doc_ids & pd_doc_ids)
        
        # è®¡ç®—å„ç§æŒ‡æ ‡
        rank_corr = self.calculate_rank_correlation(es_results, pd_results)
        score_corr, avg_score_diff = self.calculate_score_correlation(es_results, pd_results)
        top_k_overlap = self.calculate_top_k_overlap(es_results, pd_results)
        
        return ComparisonMetrics(
            total_es_results=total_es,
            total_pd_results=total_pd,
            common_docs=common_docs,
            rank_correlation=rank_corr,
            score_correlation=score_corr,
            avg_score_diff=avg_score_diff,
            top_k_overlap=top_k_overlap
        )
    
    def print_detailed_comparison(self, query_text: str, es_results: List[SearchResult], 
                                pd_results: List[SearchResult], metrics: ComparisonMetrics):
        """æ‰“å°è¯¦ç»†çš„æ¯”è¾ƒç»“æœ"""
        print(f"\n{'='*80}")
        print(f"æŸ¥è¯¢: '{query_text}'")
        print(f"{'='*80}")
        
        # åŸºæœ¬ç»Ÿè®¡
        print(f"\nğŸ“Š åŸºæœ¬ç»Ÿè®¡:")
        print(f"  ESç»“æœæ•°é‡: {metrics.total_es_results}")
        print(f"  ParadeDBç»“æœæ•°é‡: {metrics.total_pd_results}")
        print(f"  å…±åŒæ–‡æ¡£æ•°é‡: {metrics.common_docs}")
        print(f"  æ–‡æ¡£é‡å ç‡: {metrics.common_docs/max(metrics.total_es_results, metrics.total_pd_results, 1)*100:.1f}%")
        
        # ç›¸å…³æ€§æŒ‡æ ‡
        print(f"\nğŸ”— ç›¸å…³æ€§æŒ‡æ ‡:")
        print(f"  æ’åç›¸å…³æ€§ (Spearman): {metrics.rank_correlation:.3f}")
        print(f"  åˆ†æ•°ç›¸å…³æ€§ (Pearson): {metrics.score_correlation:.3f}")
        print(f"  å¹³å‡åˆ†æ•°å·®å¼‚: {metrics.avg_score_diff:.3f}")
        
        # Top-Ké‡å ç‡
        print(f"\nğŸ¯ Top-Ké‡å ç‡:")
        for k, overlap in metrics.top_k_overlap.items():
            print(f"  Top-{k}: {overlap*100:.1f}%")
        
        # è¯¦ç»†ç»“æœå¯¹æ¯”ï¼ˆå‰10æ¡ï¼‰
        print(f"\nğŸ“‹ è¯¦ç»†ç»“æœå¯¹æ¯” (å‰10æ¡):")
        print(f"{'æ’å':<4} {'ESæ–‡æ¡£ID':<20} {'ESåˆ†æ•°':<8} {'PDæ–‡æ¡£ID':<20} {'PDåˆ†æ•°':<8} {'åŒ¹é…':<4}")
        print("-" * 80)
        
        max_results = min(10, max(len(es_results), len(pd_results)))
        for i in range(max_results):
            es_doc = es_results[i] if i < len(es_results) else None
            pd_doc = pd_results[i] if i < len(pd_results) else None
            
            es_id = es_doc.doc_id[:18] + ".." if es_doc and len(es_doc.doc_id) > 20 else (es_doc.doc_id if es_doc else "-")
            es_score = f"{es_doc.score:.3f}" if es_doc else "-"
            
            pd_id = pd_doc.doc_id[:18] + ".." if pd_doc and len(pd_doc.doc_id) > 20 else (pd_doc.doc_id if pd_doc else "-")
            pd_score = f"{pd_doc.score:.3f}" if pd_doc else "-"
            
            match = "âœ“" if es_doc and pd_doc and es_doc.doc_id == pd_doc.doc_id else "âœ—"
            
            print(f"{i+1:<4} {es_id:<20} {es_score:<8} {pd_id:<20} {pd_score:<8} {match:<4}")
    
    def run_comparison_test(self, index_name: str, kb_ids: List[str], 
                           test_queries: List[str], vector_weights: List[float] = [0.3, 0.5, 0.7]):
        """è¿è¡Œå®Œæ•´çš„æ¯”è¾ƒæµ‹è¯•"""
        print(f"\nğŸš€ å¼€å§‹æœç´¢å¼•æ“æ¯”è¾ƒæµ‹è¯•")
        print(f"ç´¢å¼•åç§°: {index_name}")
        print(f"çŸ¥è¯†åº“ID: {kb_ids}")
        print(f"æµ‹è¯•æŸ¥è¯¢æ•°é‡: {len(test_queries)}")
        print(f"å‘é‡æƒé‡é…ç½®: {vector_weights}")
        
        if not self.es_conn and not self.pd_conn:
            logger.error("âŒ æ²¡æœ‰å¯ç”¨çš„æœç´¢å¼•æ“è¿æ¥")
            return
        
        all_metrics = []
        
        for query_idx, query_text in enumerate(test_queries):
            print(f"\nğŸ” æµ‹è¯•æŸ¥è¯¢ {query_idx + 1}/{len(test_queries)}: '{query_text}'")
            
            for weight_idx, vector_weight in enumerate(vector_weights):
                print(f"\n  ğŸ“Š å‘é‡æƒé‡: {vector_weight}")
                
                es_results = []
                pd_results = []
                
                # ESæœç´¢
                if self.es_conn:
                    try:
                        es_results = self.search_with_engine(
                            "ES", self.es_conn, index_name, kb_ids, 
                            query_text, vector_weight, limit=20
                        )
                    except Exception as e:
                        logger.error(f"ESæœç´¢å¤±è´¥: {e}")
                
                # ParadeDBæœç´¢
                if self.pd_conn:
                    try:
                        pd_results = self.search_with_engine(
                            "ParadeDB", self.pd_conn, index_name, kb_ids, 
                            query_text, vector_weight, limit=20
                        )
                    except Exception as e:
                        logger.error(f"ParadeDBæœç´¢å¤±è´¥: {e}")
                
                # æ¯”è¾ƒç»“æœ
                if es_results and pd_results:
                    metrics = self.compare_search_results(es_results, pd_results)
                    all_metrics.append({
                        'query': query_text,
                        'vector_weight': vector_weight,
                        'metrics': metrics
                    })
                    
                    # æ‰“å°è¯¦ç»†æ¯”è¾ƒ
                    self.print_detailed_comparison(
                        f"{query_text} (æƒé‡:{vector_weight})", 
                        es_results, pd_results, metrics
                    )
                elif es_results:
                    print(f"    âš ï¸ åªæœ‰ESè¿”å›äº†ç»“æœ ({len(es_results)}æ¡)")
                elif pd_results:
                    print(f"    âš ï¸ åªæœ‰ParadeDBè¿”å›äº†ç»“æœ ({len(pd_results)}æ¡)")
                else:
                    print(f"    âŒ ä¸¤ä¸ªå¼•æ“éƒ½æ²¡æœ‰è¿”å›ç»“æœ")
        
        # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
        self.generate_summary_report(all_metrics)
    
    def generate_summary_report(self, all_metrics: List[Dict]):
        """ç”Ÿæˆæ€»ç»“æŠ¥å‘Š"""
        if not all_metrics:
            print("\nâŒ æ²¡æœ‰å¯ç”¨çš„æ¯”è¾ƒæ•°æ®")
            return
        
        print(f"\n{'='*80}")
        print(f"ğŸ“ˆ æ€»ç»“æŠ¥å‘Š")
        print(f"{'='*80}")
        
        # è®¡ç®—å¹³å‡æŒ‡æ ‡
        avg_rank_corr = np.mean([m['metrics'].rank_correlation for m in all_metrics])
        avg_score_corr = np.mean([m['metrics'].score_correlation for m in all_metrics])
        avg_score_diff = np.mean([m['metrics'].avg_score_diff for m in all_metrics])
        avg_common_docs = np.mean([m['metrics'].common_docs for m in all_metrics])
        
        print(f"\nğŸ¯ å¹³å‡æŒ‡æ ‡:")
        print(f"  å¹³å‡æ’åç›¸å…³æ€§: {avg_rank_corr:.3f}")
        print(f"  å¹³å‡åˆ†æ•°ç›¸å…³æ€§: {avg_score_corr:.3f}")
        print(f"  å¹³å‡åˆ†æ•°å·®å¼‚: {avg_score_diff:.3f}")
        print(f"  å¹³å‡å…±åŒæ–‡æ¡£æ•°: {avg_common_docs:.1f}")
        
        # æŒ‰å‘é‡æƒé‡åˆ†ç»„åˆ†æ
        weight_groups = defaultdict(list)
        for m in all_metrics:
            weight_groups[m['vector_weight']].append(m['metrics'])
        
        print(f"\nğŸ“Š æŒ‰å‘é‡æƒé‡åˆ†æ:")
        for weight, metrics_list in weight_groups.items():
            avg_rank = np.mean([m.rank_correlation for m in metrics_list])
            avg_top5 = np.mean([m.top_k_overlap.get(5, 0) for m in metrics_list])
            print(f"  æƒé‡ {weight}: æ’åç›¸å…³æ€§={avg_rank:.3f}, Top-5é‡å ç‡={avg_top5*100:.1f}%")
        
        # ä¸€è‡´æ€§è¯„ä¼°
        print(f"\nâœ… ä¸€è‡´æ€§è¯„ä¼°:")
        if avg_rank_corr > 0.7:
            print(f"  ğŸŸ¢ æ’åä¸€è‡´æ€§: ä¼˜ç§€ ({avg_rank_corr:.3f})")
        elif avg_rank_corr > 0.5:
            print(f"  ğŸŸ¡ æ’åä¸€è‡´æ€§: è‰¯å¥½ ({avg_rank_corr:.3f})")
        else:
            print(f"  ğŸ”´ æ’åä¸€è‡´æ€§: éœ€è¦æ”¹è¿› ({avg_rank_corr:.3f})")
        
        if avg_score_corr > 0.7:
            print(f"  ğŸŸ¢ åˆ†æ•°ä¸€è‡´æ€§: ä¼˜ç§€ ({avg_score_corr:.3f})")
        elif avg_score_corr > 0.5:
            print(f"  ğŸŸ¡ åˆ†æ•°ä¸€è‡´æ€§: è‰¯å¥½ ({avg_score_corr:.3f})")
        else:
            print(f"  ğŸ”´ åˆ†æ•°ä¸€è‡´æ€§: éœ€è¦æ”¹è¿› ({avg_score_corr:.3f})")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” ESä¸ParadeDBæœç´¢ç»“æœå¯¹æ¯”éªŒè¯å·¥å…·")
    print("=" * 50)
    
    # éªŒè¯é…ç½®
    if CONFIG:
        errors = validate_config()
        if errors:
            print("âŒ é…ç½®éªŒè¯å¤±è´¥:")
            for error in errors:
                print(f"  - {error}")
            return
        print("âœ… é…ç½®éªŒè¯é€šè¿‡")
    
    # åˆå§‹åŒ–æ¯”è¾ƒå™¨
    try:
        comparator = SearchEngineComparator()
    except Exception as e:
        logger.error(f"åˆå§‹åŒ–å¤±è´¥: {e}")
        return
    
    # è·å–æµ‹è¯•å‚æ•° - ä¼˜å…ˆçº§ï¼šè‡ªåŠ¨ç”Ÿæˆé…ç½® > æ‰‹åŠ¨é…ç½® > é»˜è®¤é…ç½®
    try:
        from test_kb_config import COMPARISON_CONFIG
        index_name = COMPARISON_CONFIG['index_name']
        kb_ids = COMPARISON_CONFIG['kb_ids']
        test_queries = COMPARISON_CONFIG['test_queries']
        vector_weights = COMPARISON_CONFIG['vector_weights']
        print(f"ğŸ“‹ ä½¿ç”¨è‡ªåŠ¨ç”Ÿæˆçš„æµ‹è¯•é…ç½®")
    except ImportError:
        if CONFIG and 'test' in CONFIG:
            test_config = CONFIG['test']
            index_name = test_config['index_name']
            kb_ids = test_config['kb_ids']
            test_queries = test_config['test_queries']
            vector_weights = test_config['vector_weights']
            print(f"ğŸ“‹ ä½¿ç”¨æ‰‹åŠ¨é…ç½®æ–‡ä»¶ä¸­çš„å‚æ•°")
        else:
            # é»˜è®¤é…ç½®
            print("âš ï¸ ä½¿ç”¨é»˜è®¤æµ‹è¯•å‚æ•°")
            print("ğŸ’¡ å»ºè®®å…ˆè¿è¡Œ python simple_kb_setup.py åˆ›å»ºæµ‹è¯•æ•°æ®")
            index_name = "ragflow_6a2a5a8c00a611f0883a0242ac140006"
            kb_ids = ["6a2a5a8c-00a6-11f0-883a-0242ac140006"]
            test_queries = [
                "æœºå™¨äºº", "äººå·¥æ™ºèƒ½", "è‡ªç„¶è¯­è¨€å¤„ç†", "æ·±åº¦å­¦ä¹ ç®—æ³•", "æ•°æ®åˆ†ææ–¹æ³•",
                "zendesk", "customer service", "æŠ€æœ¯æ–‡æ¡£", "ç”¨æˆ·æŒ‡å—", "APIæ¥å£"
            ]
            vector_weights = [0.3, 0.5, 0.7]
    
    print(f"  ç´¢å¼•åç§°: {index_name}")
    print(f"  çŸ¥è¯†åº“ID: {kb_ids}")
    print(f"  æµ‹è¯•æŸ¥è¯¢æ•°: {len(test_queries)}")
    print(f"  å‘é‡æƒé‡: {vector_weights}")
    
    # è¿è¡Œæ¯”è¾ƒæµ‹è¯•
    try:
        comparator.run_comparison_test(
            index_name=index_name,
            kb_ids=kb_ids,
            test_queries=test_queries,
            vector_weights=vector_weights
        )
    except Exception as e:
        logger.error(f"æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 