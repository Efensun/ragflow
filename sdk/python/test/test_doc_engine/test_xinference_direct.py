#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç›´æ¥æµ‹è¯•Xinference embeddingæ¨¡å‹è¿æ¥

è¿™ä¸ªè„šæœ¬ç”¨äºéªŒè¯æ˜¯å¦å¯ä»¥ç»•è¿‡RAGFlowæƒé™æ§åˆ¶ï¼Œç›´æ¥è°ƒç”¨Xinferenceçš„jina-embeddings-v3æ¨¡å‹
"""

import os
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def test_xinference_direct():
    """ç›´æ¥æµ‹è¯•Xinferenceè¿æ¥"""
    print("ğŸ§ª æµ‹è¯•ç›´æ¥è°ƒç”¨Xinference embeddingæ¨¡å‹")
    print("=" * 50)
    
    # æ–¹æ³•1: ä½¿ç”¨RAGFlowçš„XinferenceEmbedç±»
    print("\n1ï¸âƒ£ æµ‹è¯•RAGFlow XinferenceEmbedç±»")
    try:
        from rag.llm.embedding_model import XinferenceEmbed
        
        xinference_embed = XinferenceEmbed(
            key="",  # Xinferenceé€šå¸¸ä¸éœ€è¦API key
            model_name="jina-embeddings-v3",
            base_url="http://120.77.38.66:8008/"  # ç”¨æˆ·æä¾›çš„Xinferenceåœ°å€
        )
        
        # æµ‹è¯•embedding
        test_texts = ["äººå·¥æ™ºèƒ½", "æœºå™¨å­¦ä¹ ", "è‡ªç„¶è¯­è¨€å¤„ç†"]
        embeddings, tokens = xinference_embed.encode(test_texts)
        
        print(f"âœ… RAGFlow XinferenceEmbed æˆåŠŸ!")
        print(f"  å‘é‡ç»´åº¦: {len(embeddings[0])}")
        print(f"  æµ‹è¯•æ–‡æœ¬æ•°: {len(test_texts)}")
        print(f"  è¿”å›å‘é‡æ•°: {len(embeddings)}")
        print(f"  Tokenæ¶ˆè€—: {tokens}")
        print(f"  ç¬¬ä¸€ä¸ªå‘é‡å‰5ç»´: {embeddings[0][:5]}")
        
        return True, len(embeddings[0])
        
    except Exception as e:
        print(f"âŒ RAGFlow XinferenceEmbed å¤±è´¥: {e}")
    
    # æ–¹æ³•2: ä½¿ç”¨OpenAIå®¢æˆ·ç«¯ç›´æ¥è¿æ¥
    print("\n2ï¸âƒ£ æµ‹è¯•OpenAIå®¢æˆ·ç«¯ç›´æ¥è¿æ¥")
    try:
        from openai import OpenAI
        
        client = OpenAI(api_key="empty", base_url="http://120.77.38.66:8008/v1")
        
        # æµ‹è¯•embedding
        response = client.embeddings.create(
            input=["äººå·¥æ™ºèƒ½", "æœºå™¨å­¦ä¹ "],
            model="jina-embeddings-v3"
        )
        
        print(f"âœ… OpenAIå®¢æˆ·ç«¯ æˆåŠŸ!")
        print(f"  å‘é‡ç»´åº¦: {len(response.data[0].embedding)}")
        print(f"  è¿”å›æ•°æ®æ•°: {len(response.data)}")
        print(f"  ç¬¬ä¸€ä¸ªå‘é‡å‰5ç»´: {response.data[0].embedding[:5]}")
        
        if hasattr(response, 'usage'):
            print(f"  Tokenæ¶ˆè€—: {response.usage.total_tokens}")
        
        return True, len(response.data[0].embedding)
        
    except Exception as e:
        print(f"âŒ OpenAIå®¢æˆ·ç«¯ å¤±è´¥: {e}")
    
    # æ–¹æ³•3: æµ‹è¯•å…¶ä»–å¯èƒ½çš„åœ°å€
    print("\n3ï¸âƒ£ æµ‹è¯•å…¶ä»–Xinferenceåœ°å€")
    xinference_urls = [
        "http://120.77.38.66:8008/",
        "http://120.77.38.66:8008/v1",
        "http://127.0.0.1:9997",
        "http://0.0.0.0:9997",
        "http://localhost:9997/v1"
    ]
    
    for base_url in xinference_urls:
        try:
            from rag.llm.embedding_model import XinferenceEmbed
            
            xinference_embed = XinferenceEmbed(
                key="",
                model_name="jina-embeddings-v3",
                base_url=base_url
            )
            
            embeddings, tokens = xinference_embed.encode(["æµ‹è¯•"])
            
            print(f"âœ… åœ°å€ {base_url} æˆåŠŸ!")
            print(f"  å‘é‡ç»´åº¦: {len(embeddings[0])}")
            
            return True, len(embeddings[0])
            
        except Exception as e:
            print(f"âŒ åœ°å€ {base_url} å¤±è´¥: {e}")
    
    return False, None

def test_xinference_service():
    """æµ‹è¯•XinferenceæœåŠ¡çŠ¶æ€"""
    print("\nğŸ” æ£€æŸ¥XinferenceæœåŠ¡çŠ¶æ€")
    print("-" * 30)
    
    try:
        import requests
        
        # æ£€æŸ¥XinferenceæœåŠ¡æ˜¯å¦è¿è¡Œ
        response = requests.get("http://120.77.38.66:8008/v1/models", timeout=5)
        
        if response.status_code == 200:
            models = response.json()
            print(f"âœ… XinferenceæœåŠ¡è¿è¡Œæ­£å¸¸")
            print(f"  å¯ç”¨æ¨¡å‹æ•°: {len(models.get('data', []))}")
            
            # æŸ¥æ‰¾jina-embeddings-v3æ¨¡å‹
            jina_models = [m for m in models.get('data', []) if 'jina' in m.get('id', '').lower()]
            if jina_models:
                print(f"  æ‰¾åˆ°Jinaæ¨¡å‹: {[m['id'] for m in jina_models]}")
            else:
                print(f"  âš ï¸ æœªæ‰¾åˆ°jina-embeddings-v3æ¨¡å‹")
                print(f"  å¯ç”¨æ¨¡å‹: {[m.get('id', 'unknown') for m in models.get('data', [])]}")
        else:
            print(f"âŒ XinferenceæœåŠ¡å“åº”å¼‚å¸¸: {response.status_code}")
            
    except requests.exceptions.ConnectionError:
        print(f"âŒ æ— æ³•è¿æ¥åˆ°XinferenceæœåŠ¡ (http://120.77.38.66:8008)")
        print(f"ğŸ’¡ è¯·ç¡®ä¿XinferenceæœåŠ¡æ­£åœ¨è¿è¡Œ:")
        print(f"   xinference-local --host 0.0.0.0 --port 8008")
    except Exception as e:
        print(f"âŒ æ£€æŸ¥XinferenceæœåŠ¡å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ Xinferenceç›´æ¥è°ƒç”¨æµ‹è¯•å·¥å…·")
    print("=" * 50)
    
    # æ£€æŸ¥æœåŠ¡çŠ¶æ€
    test_xinference_service()
    
    # æµ‹è¯•ç›´æ¥è°ƒç”¨
    success, vector_dim = test_xinference_direct()
    
    print(f"\nğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“")
    print("=" * 30)
    
    if success:
        print(f"âœ… æˆåŠŸç»•è¿‡æƒé™æ§åˆ¶ï¼Œç›´æ¥è°ƒç”¨Xinference!")
        print(f"  å‘é‡ç»´åº¦: {vector_dim}")
        print(f"  æ¨¡å‹: jina-embeddings-v3")
        print(f"\nğŸ’¡ ç°åœ¨å¯ä»¥è¿è¡Œ:")
        print(f"  python sdk/python/test/test_doc_engine/simple_kb_setup.py")
        print(f"  python sdk/python/test/test_doc_engine/quick_search_test.py")
    else:
        print(f"âŒ æ— æ³•ç›´æ¥è°ƒç”¨Xinference")
        print(f"\nğŸ”§ æ•…éšœæ’é™¤å»ºè®®:")
        print(f"  1. ç¡®ä¿XinferenceæœåŠ¡æ­£åœ¨è¿è¡Œ:")
        print(f"     xinference-local --host 0.0.0.0 --port 8008")
        print(f"  2. å¯åŠ¨jina-embeddings-v3æ¨¡å‹:")
        print(f"     xinference launch --model-name jina-embeddings-v3 --model-type embedding")
        print(f"  3. æ£€æŸ¥é˜²ç«å¢™è®¾ç½®ï¼Œç¡®ä¿ç«¯å£9997å¯è®¿é—®")
        print(f"  4. æˆ–è€…å®‰è£…sentence-transformersä½œä¸ºå¤‡é€‰:")
        print(f"     pip install sentence-transformers")

if __name__ == "__main__":
    main() 