#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çŸ¥è¯†åº“éš”ç¦»æµ‹è¯•è„šæœ¬

éªŒè¯ä¸åŒçŸ¥è¯†åº“çš„æ–‡æ¡£æ˜¯å¦æ­£ç¡®éš”ç¦»ï¼Œæœç´¢æ—¶æ˜¯å¦åªè¿”å›æŒ‡å®šçŸ¥è¯†åº“çš„æ–‡æ¡£
"""

import os
import sys
import time
import logging
from typing import List, Dict

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from rag import settings
from rag.utils.es_conn import ESConnection
from rag.utils.pd_conn import PDConnection
from rag.utils.doc_store_conn import MatchTextExpr, OrderByExpr
from rag.nlp import rag_tokenizer
import uuid

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class KBIsolationTester:
    """çŸ¥è¯†åº“éš”ç¦»æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.es_conn = None
        self.pd_conn = None
        self.init_connections()
    
    def init_connections(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¿æ¥"""
        try:
            if hasattr(settings, 'ES') and settings.ES.get('hosts'):
                self.es_conn = ESConnection()
                print("âœ… ESè¿æ¥æˆåŠŸ")
        except Exception as e:
            print(f"âŒ ESè¿æ¥å¤±è´¥: {e}")
        
        try:
            if hasattr(settings, 'PARADEDB') and settings.PARADEDB.get('host'):
                self.pd_conn = PDConnection()
                print("âœ… ParadeDBè¿æ¥æˆåŠŸ")
        except Exception as e:
            print(f"âŒ ParadeDBè¿æ¥å¤±è´¥: {e}")
    
    def verify_data_insertion(self, conn, engine_name: str, index_name: str, kb_id: str, expected_count: int):
        """éªŒè¯æ•°æ®æ’å…¥æ˜¯å¦æˆåŠŸ"""
        try:
            # ä½¿ç”¨ç®€å•çš„æŸ¥è¯¢æ¥éªŒè¯æ•°æ®
            res = conn.search(
                selectFields=["id", "title_tks", "kb_id"],
                highlightFields=[],
                condition={"available_int": 1},
                matchExprs=[],  # ç©ºçš„åŒ¹é…è¡¨è¾¾å¼ï¼Œè¿”å›æ‰€æœ‰æ–‡æ¡£
                orderBy=OrderByExpr(),
                offset=0,
                limit=100,
                indexNames=index_name,
                knowledgebaseIds=[kb_id]
            )
            
            total = conn.getTotal(res) if hasattr(conn, 'getTotal') else len(res.get("hits", {}).get("hits", []))
            hits = res.get("hits", {}).get("hits", [])
            
            print(f"  {engine_name} çŸ¥è¯†åº“ {kb_id[:8]}... éªŒè¯:")
            print(f"    æ€»æ–‡æ¡£æ•°: {total}")
            print(f"    è¿”å›æ–‡æ¡£æ•°: {len(hits)}")
            print(f"    é¢„æœŸæ–‡æ¡£æ•°: {expected_count}")
            
            if hits:
                print(f"    æ ·æœ¬æ–‡æ¡£:")
                for i, hit in enumerate(hits[:2]):
                    source = hit.get("_source", {})
                    print(f"      {i+1}. ID: {hit.get('_id', '')[:8]}...")
                    print(f"         æ ‡é¢˜: {source.get('title_tks', '')}")
                    print(f"         KB_ID: {source.get('kb_id', '')[:8]}...")
            
            return total == expected_count
            
        except Exception as e:
            print(f"  âŒ {engine_name} æ•°æ®éªŒè¯å¤±è´¥: {e}")
            return False
    
    def create_test_data(self, index_name: str) -> Dict[str, List[str]]:
        """åˆ›å»ºæµ‹è¯•æ•°æ®ï¼šä¸¤ä¸ªä¸åŒçš„çŸ¥è¯†åº“"""
        kb1_id = str(uuid.uuid4())
        kb2_id = str(uuid.uuid4())
        
        print(f"\nğŸ“ åˆ›å»ºæµ‹è¯•æ•°æ®:")
        print(f"  çŸ¥è¯†åº“1 ID: {kb1_id}")
        print(f"  çŸ¥è¯†åº“2 ID: {kb2_id}")
        
        # çŸ¥è¯†åº“1çš„æ–‡æ¡£ - ä½¿ç”¨æ›´ä¸°å¯Œçš„å†…å®¹
        kb1_docs = [
            {
                "id": str(uuid.uuid4()),
                "kb_id": kb1_id,
                "title_tks": "äººå·¥æ™ºèƒ½åŸºç¡€çŸ¥è¯†æ–‡æ¡£",
                "content_with_weight": "è¿™æ˜¯çŸ¥è¯†åº“1çš„ç¬¬ä¸€ä¸ªæ–‡æ¡£ï¼ŒåŒ…å«äººå·¥æ™ºèƒ½ã€æœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ ç›¸å…³å†…å®¹ã€‚äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„é‡è¦åˆ†æ”¯ã€‚",
                "content_ltks": "è¿™æ˜¯ çŸ¥è¯†åº“ 1 çš„ ç¬¬ä¸€ä¸ª æ–‡æ¡£ åŒ…å« äººå·¥æ™ºèƒ½ æœºå™¨å­¦ä¹  æ·±åº¦å­¦ä¹  ç›¸å…³ å†…å®¹ äººå·¥æ™ºèƒ½ æ˜¯ è®¡ç®—æœºç§‘å­¦ çš„ é‡è¦ åˆ†æ”¯",
                "content_sm_ltks": "è¿™æ˜¯ çŸ¥è¯†åº“ 1 çš„ ç¬¬ä¸€ä¸ª æ–‡æ¡£ åŒ…å« äººå·¥ æ™ºèƒ½ æœºå™¨ å­¦ä¹  æ·±åº¦ å­¦ä¹  ç›¸å…³ å†…å®¹ äººå·¥ æ™ºèƒ½ æ˜¯ è®¡ç®—æœº ç§‘å­¦ çš„ é‡è¦ åˆ†æ”¯",
                "available_int": 1,
                "create_time": time.strftime("%Y-%m-%d %H:%M:%S"),
                "create_timestamp_flt": time.time()
            },
            {
                "id": str(uuid.uuid4()),
                "kb_id": kb1_id,
                "title_tks": "æœºå™¨å­¦ä¹ ç®—æ³•è¯¦è§£æ–‡æ¡£", 
                "content_with_weight": "è¿™æ˜¯çŸ¥è¯†åº“1çš„ç¬¬äºŒä¸ªæ–‡æ¡£ï¼ŒåŒ…å«æœºå™¨å­¦ä¹ ç®—æ³•ã€ç¥ç»ç½‘ç»œã€æ•°æ®æŒ–æ˜ç›¸å…³å†…å®¹ã€‚æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„æ ¸å¿ƒæŠ€æœ¯ã€‚",
                "content_ltks": "è¿™æ˜¯ çŸ¥è¯†åº“ 1 çš„ ç¬¬äºŒä¸ª æ–‡æ¡£ åŒ…å« æœºå™¨å­¦ä¹  ç®—æ³• ç¥ç»ç½‘ç»œ æ•°æ®æŒ–æ˜ ç›¸å…³ å†…å®¹ æœºå™¨å­¦ä¹  æ˜¯ äººå·¥æ™ºèƒ½ çš„ æ ¸å¿ƒ æŠ€æœ¯",
                "content_sm_ltks": "è¿™æ˜¯ çŸ¥è¯†åº“ 1 çš„ ç¬¬äºŒä¸ª æ–‡æ¡£ åŒ…å« æœºå™¨ å­¦ä¹  ç®—æ³• ç¥ç» ç½‘ç»œ æ•°æ® æŒ–æ˜ ç›¸å…³ å†…å®¹ æœºå™¨ å­¦ä¹  æ˜¯ äººå·¥ æ™ºèƒ½ çš„ æ ¸å¿ƒ æŠ€æœ¯",
                "available_int": 1,
                "create_time": time.strftime("%Y-%m-%d %H:%M:%S"),
                "create_timestamp_flt": time.time() + 1
            }
        ]
        
        # çŸ¥è¯†åº“2çš„æ–‡æ¡£ - ä½¿ç”¨ä¸åŒä¸»é¢˜çš„å†…å®¹
        kb2_docs = [
            {
                "id": str(uuid.uuid4()),
                "kb_id": kb2_id,
                "title_tks": "åŒºå—é“¾æŠ€æœ¯åŸç†æ–‡æ¡£",
                "content_with_weight": "è¿™æ˜¯çŸ¥è¯†åº“2çš„ç¬¬ä¸€ä¸ªæ–‡æ¡£ï¼ŒåŒ…å«åŒºå—é“¾æŠ€æœ¯ã€åŠ å¯†è´§å¸ã€åˆ†å¸ƒå¼ç³»ç»Ÿç›¸å…³å†…å®¹ã€‚åŒºå—é“¾æ˜¯åˆ†å¸ƒå¼è´¦æœ¬æŠ€æœ¯ã€‚",
                "content_ltks": "è¿™æ˜¯ çŸ¥è¯†åº“ 2 çš„ ç¬¬ä¸€ä¸ª æ–‡æ¡£ åŒ…å« åŒºå—é“¾ æŠ€æœ¯ åŠ å¯†è´§å¸ åˆ†å¸ƒå¼ç³»ç»Ÿ ç›¸å…³ å†…å®¹ åŒºå—é“¾ æ˜¯ åˆ†å¸ƒå¼ è´¦æœ¬ æŠ€æœ¯",
                "content_sm_ltks": "è¿™æ˜¯ çŸ¥è¯†åº“ 2 çš„ ç¬¬ä¸€ä¸ª æ–‡æ¡£ åŒ…å« åŒºå—é“¾ æŠ€æœ¯ åŠ å¯† è´§å¸ åˆ†å¸ƒå¼ ç³»ç»Ÿ ç›¸å…³ å†…å®¹ åŒºå—é“¾ æ˜¯ åˆ†å¸ƒå¼ è´¦æœ¬ æŠ€æœ¯",
                "available_int": 1,
                "create_time": time.strftime("%Y-%m-%d %H:%M:%S"),
                "create_timestamp_flt": time.time() + 2
            },
            {
                "id": str(uuid.uuid4()),
                "kb_id": kb2_id,
                "title_tks": "äº‘è®¡ç®—å¹³å°æ¶æ„æ–‡æ¡£",
                "content_with_weight": "è¿™æ˜¯çŸ¥è¯†åº“2çš„ç¬¬äºŒä¸ªæ–‡æ¡£ï¼ŒåŒ…å«äº‘è®¡ç®—å¹³å°ã€å¾®æœåŠ¡æ¶æ„ã€å®¹å™¨æŠ€æœ¯ç›¸å…³å†…å®¹ã€‚äº‘è®¡ç®—æä¾›å¼¹æ€§è®¡ç®—èµ„æºã€‚", 
                "content_ltks": "è¿™æ˜¯ çŸ¥è¯†åº“ 2 çš„ ç¬¬äºŒä¸ª æ–‡æ¡£ åŒ…å« äº‘è®¡ç®— å¹³å° å¾®æœåŠ¡ æ¶æ„ å®¹å™¨ æŠ€æœ¯ ç›¸å…³ å†…å®¹ äº‘è®¡ç®— æä¾› å¼¹æ€§ è®¡ç®— èµ„æº",
                "content_sm_ltks": "è¿™æ˜¯ çŸ¥è¯†åº“ 2 çš„ ç¬¬äºŒä¸ª æ–‡æ¡£ åŒ…å« äº‘ è®¡ç®— å¹³å° å¾® æœåŠ¡ æ¶æ„ å®¹å™¨ æŠ€æœ¯ ç›¸å…³ å†…å®¹ äº‘ è®¡ç®— æä¾› å¼¹æ€§ è®¡ç®— èµ„æº",
                "available_int": 1,
                "create_time": time.strftime("%Y-%m-%d %H:%M:%S"),
                "create_timestamp_flt": time.time() + 3
            }
        ]
        
        # æ’å…¥æ•°æ®åˆ°ES
        if self.es_conn:
            try:
                print(f"  æ’å…¥æ•°æ®åˆ°ES...")
                errors1 = self.es_conn.insert(kb1_docs, index_name, kb1_id)
                errors2 = self.es_conn.insert(kb2_docs, index_name, kb2_id)
                if errors1 or errors2:
                    print(f"  âš ï¸ ESæ’å…¥æœ‰é”™è¯¯: KB1={errors1}, KB2={errors2}")
                else:
                    print(f"  âœ… ESæ•°æ®æ’å…¥æˆåŠŸ")
            except Exception as e:
                print(f"  âŒ ESæ•°æ®æ’å…¥å¤±è´¥: {e}")
        
        # æ’å…¥æ•°æ®åˆ°ParadeDB
        if self.pd_conn:
            try:
                print(f"  æ’å…¥æ•°æ®åˆ°ParadeDB...")
                errors1 = self.pd_conn.insert(kb1_docs, index_name, kb1_id)
                errors2 = self.pd_conn.insert(kb2_docs, index_name, kb2_id)
                if errors1 or errors2:
                    print(f"  âš ï¸ ParadeDBæ’å…¥æœ‰é”™è¯¯: KB1={errors1}, KB2={errors2}")
                else:
                    print(f"  âœ… ParadeDBæ•°æ®æ’å…¥æˆåŠŸ")
            except Exception as e:
                print(f"  âŒ ParadeDBæ•°æ®æ’å…¥å¤±è´¥: {e}")
        
        # ç­‰å¾…ç´¢å¼•åˆ·æ–°
        print(f"  â³ ç­‰å¾…ç´¢å¼•åˆ·æ–°...")
        time.sleep(5)
        
        # éªŒè¯æ•°æ®æ’å…¥
        print(f"\nğŸ” éªŒè¯æ•°æ®æ’å…¥:")
        if self.es_conn:
            self.verify_data_insertion(self.es_conn, "ES", index_name, kb1_id, 2)
            self.verify_data_insertion(self.es_conn, "ES", index_name, kb2_id, 2)
        
        if self.pd_conn:
            self.verify_data_insertion(self.pd_conn, "ParadeDB", index_name, kb1_id, 2)
            self.verify_data_insertion(self.pd_conn, "ParadeDB", index_name, kb2_id, 2)
        
        return {
            "kb1_id": kb1_id,
            "kb2_id": kb2_id,
            "kb1_doc_ids": [doc["id"] for doc in kb1_docs],
            "kb2_doc_ids": [doc["id"] for doc in kb2_docs]
        }
    
    def test_kb_isolation(self, index_name: str, test_data: Dict):
        """æµ‹è¯•çŸ¥è¯†åº“éš”ç¦»"""
        kb1_id = test_data["kb1_id"]
        kb2_id = test_data["kb2_id"]
        kb1_doc_ids = set(test_data["kb1_doc_ids"])
        kb2_doc_ids = set(test_data["kb2_doc_ids"])
        
        print(f"\nğŸ§ª æµ‹è¯•çŸ¥è¯†åº“éš”ç¦»")
        print(f"çŸ¥è¯†åº“1 ID: {kb1_id}")
        print(f"çŸ¥è¯†åº“2 ID: {kb2_id}")
        print(f"çŸ¥è¯†åº“1æ–‡æ¡£æ•°: {len(kb1_doc_ids)}")
        print(f"çŸ¥è¯†åº“2æ–‡æ¡£æ•°: {len(kb2_doc_ids)}")
        
        # æµ‹è¯•ESéš”ç¦»
        if self.es_conn:
            print(f"\nğŸ“Š ESéš”ç¦»æµ‹è¯•:")
            self._test_engine_isolation(self.es_conn, "ES", index_name, kb1_id, kb2_id, kb1_doc_ids, kb2_doc_ids)
        
        # æµ‹è¯•ParadeDBéš”ç¦»
        if self.pd_conn:
            print(f"\nğŸ“Š ParadeDBéš”ç¦»æµ‹è¯•:")
            self._test_engine_isolation(self.pd_conn, "ParadeDB", index_name, kb1_id, kb2_id, kb1_doc_ids, kb2_doc_ids)
    
    def _test_engine_isolation(self, conn, engine_name: str, index_name: str, 
                              kb1_id: str, kb2_id: str, 
                              kb1_doc_ids: set, kb2_doc_ids: set):
        """æµ‹è¯•å•ä¸ªå¼•æ“çš„çŸ¥è¯†åº“éš”ç¦»"""
        
        # å‡†å¤‡å¤šä¸ªæµ‹è¯•æŸ¥è¯¢
        test_queries = [
            "æ–‡æ¡£",
            "çŸ¥è¯†åº“",
            "äººå·¥æ™ºèƒ½",
            "æœºå™¨å­¦ä¹ ",
            "åŒºå—é“¾",
            "äº‘è®¡ç®—"
        ]
        
        for query_text in test_queries:
            print(f"\n  ğŸ” æµ‹è¯•æŸ¥è¯¢: '{query_text}'")
            
            # å¯¹æŸ¥è¯¢æ–‡æœ¬è¿›è¡Œåˆ†è¯å¤„ç†ï¼ˆParadeDBéœ€è¦ï¼‰
            tokenized_query = rag_tokenizer.fine_grained_tokenize(rag_tokenizer.tokenize(query_text))
            print(f"    åŸå§‹æŸ¥è¯¢: {query_text}")
            print(f"    åˆ†è¯ç»“æœ: {tokenized_query}")
            
            # æµ‹è¯•1ï¼šæœç´¢çŸ¥è¯†åº“1
            try:
                print(f"    ğŸ“‹ æœç´¢çŸ¥è¯†åº“1:")
                res1 = conn.search(
                    selectFields=["id", "title_tks", "kb_id", "content_with_weight"],
                    highlightFields=[],
                    condition={"available_int": 1},
                    matchExprs=[MatchTextExpr(
                        fields=["content_with_weight^10", "title_tks^8", "content_ltks^5", "content_sm_ltks^3"],
                        matching_text=query_text,
                        topn=10,
                        extra_options={"minimum_should_match": 0.1}  # é™ä½åŒ¹é…è¦æ±‚
                    )],
                    orderBy=OrderByExpr(),
                    offset=0,
                    limit=10,
                    indexNames=index_name,
                    knowledgebaseIds=[kb1_id]
                )
                
                kb1_results = set()
                hits = res1.get("hits", {}).get("hits", [])
                print(f"      è¿”å›ç»“æœ: {len(hits)}æ¡")
                
                for hit in hits:
                    kb1_results.add(hit.get("_id"))
                    source = hit.get("_source", {})
                    score = hit.get("_score", 0)
                    print(f"        æ–‡æ¡£: {hit.get('_id')[:8]}... åˆ†æ•°:{score:.3f}")
                    print(f"        æ ‡é¢˜: {source.get('title_tks', '')}")
                    print(f"        å†…å®¹: {source.get('content_with_weight', '')[:50]}...")
                
                # éªŒè¯éš”ç¦»æ€§
                kb1_isolation_ok = kb1_results.issubset(kb1_doc_ids) if kb1_results else True
                kb1_no_leak = len(kb1_results & kb2_doc_ids) == 0
                
                print(f"      âœ… çŸ¥è¯†åº“1éš”ç¦»æ­£ç¡®: {kb1_isolation_ok}")
                print(f"      âœ… æ— çŸ¥è¯†åº“2æ³„æ¼: {kb1_no_leak}")
                
            except Exception as e:
                print(f"      âŒ çŸ¥è¯†åº“1æœç´¢å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
            
            # æµ‹è¯•2ï¼šæœç´¢çŸ¥è¯†åº“2
            try:
                print(f"    ğŸ“‹ æœç´¢çŸ¥è¯†åº“2:")
                res2 = conn.search(
                    selectFields=["id", "title_tks", "kb_id", "content_with_weight"],
                    highlightFields=[],
                    condition={"available_int": 1},
                    matchExprs=[MatchTextExpr(
                        fields=["content_with_weight^10", "title_tks^8", "content_ltks^5", "content_sm_ltks^3"],
                        matching_text=query_text,
                        topn=10,
                        extra_options={"minimum_should_match": 0.1}  # é™ä½åŒ¹é…è¦æ±‚
                    )],
                    orderBy=OrderByExpr(),
                    offset=0,
                    limit=10,
                    indexNames=index_name,
                    knowledgebaseIds=[kb2_id]
                )
                
                kb2_results = set()
                hits = res2.get("hits", {}).get("hits", [])
                print(f"      è¿”å›ç»“æœ: {len(hits)}æ¡")
                
                for hit in hits:
                    kb2_results.add(hit.get("_id"))
                    source = hit.get("_source", {})
                    score = hit.get("_score", 0)
                    print(f"        æ–‡æ¡£: {hit.get('_id')[:8]}... åˆ†æ•°:{score:.3f}")
                    print(f"        æ ‡é¢˜: {source.get('title_tks', '')}")
                    print(f"        å†…å®¹: {source.get('content_with_weight', '')[:50]}...")
                
                # éªŒè¯éš”ç¦»æ€§
                kb2_isolation_ok = kb2_results.issubset(kb2_doc_ids) if kb2_results else True
                kb2_no_leak = len(kb2_results & kb1_doc_ids) == 0
                
                print(f"      âœ… çŸ¥è¯†åº“2éš”ç¦»æ­£ç¡®: {kb2_isolation_ok}")
                print(f"      âœ… æ— çŸ¥è¯†åº“1æ³„æ¼: {kb2_no_leak}")
                
            except Exception as e:
                print(f"      âŒ çŸ¥è¯†åº“2æœç´¢å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
            
            # å¦‚æœæŸä¸ªæŸ¥è¯¢æœ‰ç»“æœï¼Œå°±ä¸éœ€è¦ç»§ç»­æµ‹è¯•å…¶ä»–æŸ¥è¯¢äº†
            if (len(hits) > 0 for hits in [res1.get("hits", {}).get("hits", []), res2.get("hits", {}).get("hits", [])]):
                print(f"    âœ… æŸ¥è¯¢ '{query_text}' æœ‰ç»“æœï¼Œéš”ç¦»æµ‹è¯•é€šè¿‡")
                break
        
        # æµ‹è¯•3ï¼šåŒæ—¶æœç´¢ä¸¤ä¸ªçŸ¥è¯†åº“
        try:
            print(f"  ğŸ” æµ‹è¯•: æœç´¢ä¸¤ä¸ªçŸ¥è¯†åº“")
            res_both = conn.search(
                selectFields=["id", "title_tks", "kb_id"],
                highlightFields=[],
                condition={"available_int": 1},
                matchExprs=[MatchTextExpr(
                    fields=["content_with_weight^10", "title_tks^8", "content_ltks^5"],
                    matching_text="æ–‡æ¡£",
                    topn=10,
                    extra_options={"minimum_should_match": 0.1}
                )],
                orderBy=OrderByExpr(),
                offset=0,
                limit=10,
                indexNames=index_name,
                knowledgebaseIds=[kb1_id, kb2_id]
            )
            
            both_results = set()
            hits = res_both.get("hits", {}).get("hits", [])
            for hit in hits:
                both_results.add(hit.get("_id"))
                source = hit.get("_source", {})
                print(f"    æ‰¾åˆ°æ–‡æ¡£: {hit.get('_id')[:8]}... KB:{source.get('kb_id', '')[:8]}... æ ‡é¢˜:{source.get('title_tks', '')}")
            
            expected_all = kb1_doc_ids | kb2_doc_ids
            print(f"  åŒçŸ¥è¯†åº“æœç´¢ç»“æœ: {len(both_results)}æ¡")
            print(f"  é¢„æœŸæ€»æ–‡æ¡£æ•°: {len(expected_all)}")
            
            both_complete = both_results == expected_all
            print(f"  âœ… åŒçŸ¥è¯†åº“æœç´¢å®Œæ•´: {both_complete}")
            
        except Exception as e:
            print(f"  âŒ åŒçŸ¥è¯†åº“æœç´¢å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”’ çŸ¥è¯†åº“éš”ç¦»æµ‹è¯•å·¥å…·")
    print("=" * 40)
    
    # åˆå§‹åŒ–æµ‹è¯•å™¨
    tester = KBIsolationTester()
    
    if not tester.es_conn and not tester.pd_conn:
        print("âŒ æ²¡æœ‰å¯ç”¨çš„æœç´¢å¼•æ“è¿æ¥")
        return
    
    # ç”Ÿæˆæµ‹è¯•ç´¢å¼•å
    tenant_id = str(uuid.uuid4()).replace('-', '')
    index_name = f"ragflow_{tenant_id}"
    
    print(f"æµ‹è¯•ç´¢å¼•: {index_name}")
    
    try:
        # åˆ›å»ºç´¢å¼•
        print(f"\nğŸ—ï¸ åˆ›å»ºç´¢å¼•:")
        if tester.es_conn:
            try:
                tester.es_conn.createIdx(index_name, "", 1024)
                print(f"  âœ… ESç´¢å¼•åˆ›å»ºæˆåŠŸ")
            except Exception as e:
                print(f"  âŒ ESç´¢å¼•åˆ›å»ºå¤±è´¥: {e}")
        
        if tester.pd_conn:
            try:
                tester.pd_conn.createIdx(index_name, "", 1024)
                print(f"  âœ… ParadeDBç´¢å¼•åˆ›å»ºæˆåŠŸ")
            except Exception as e:
                print(f"  âŒ ParadeDBç´¢å¼•åˆ›å»ºå¤±è´¥: {e}")
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        test_data = tester.create_test_data(index_name)
        
        # æµ‹è¯•éš”ç¦»æ€§
        tester.test_kb_isolation(index_name, test_data)
        
        print(f"\nğŸ‰ çŸ¥è¯†åº“éš”ç¦»æµ‹è¯•å®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # æ¸…ç†æµ‹è¯•æ•°æ®
        try:
            if tester.es_conn:
                tester.es_conn.deleteIdx(index_name, "")
            if tester.pd_conn:
                tester.pd_conn.deleteIdx(index_name, "")
            print(f"ğŸ§¹ å·²æ¸…ç†æµ‹è¯•ç´¢å¼•: {index_name}")
        except Exception as e:
            print(f"âš ï¸ æ¸…ç†ç´¢å¼•å¤±è´¥: {e}")

if __name__ == "__main__":
    main() 